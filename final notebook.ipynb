{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f2320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put Open AI API key into Python environment\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = 'AIzaSyDRwccfet2fbZASVGBB_wgjh6NLd_Z2qdo'\n",
    "\n",
    "## Put Open AI API key into Python environment\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = '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'\n",
    "\n",
    "\n",
    "## Put Open AI API key into Python environment\n",
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341b94ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd4854e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> cache_utils installed\n"
     ]
    }
   ],
   "source": [
    "from airllm import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Mahmoud Salem\\.cache\\huggingface\\hub\\models--microsoft--Phi-4-reasoning-plus. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown artichitecture: Phi3ForCausalLM, try to use Llama2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 12 files: 100%|██████████| 12/12 [00:06<00:00,  1.89it/s]\n",
      "  0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"microsoft/Phi-4-reasoning-plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc764ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from dotenv import load_dotenv\n",
    "from phi.agent import Agent\n",
    "from phi.model.groq import Groq\n",
    "from phi.tools.yfinance import YFinanceTools\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from datetime import datetime\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Custom DuckDuckGoSearchRun with predefined site restrictions\n",
    "class RestrictedDuckDuckGoSearch(DuckDuckGoSearchRun):\n",
    "    def _run(self, query: str, **kwargs) -> str:\n",
    "        # List of top 10 websites for EURUSD news\n",
    "        top_websites = [\n",
    "            \"fxstreet.com\",\n",
    "            \"investing.com\",\n",
    "            \"reuters.com\",\n",
    "            \"bloomberg.com\",\n",
    "            \"tradingview.com\",\n",
    "            \"cnbc.com\",\n",
    "            \"finance.yahoo.com\",\n",
    "            \"dailyfx.com\",\n",
    "            \"marketwatch.com\",\n",
    "            \"ig.com\"\n",
    "        ]\n",
    "        # Append site restrictions to the query using OR operator\n",
    "        site_restriction = \" | \".join(f\"site:{site}\" for site in top_websites)\n",
    "        restricted_query = f\"{query} {site_restriction}\"\n",
    "        return super()._run(restricted_query, **kwargs)\n",
    "\n",
    "web_search_agent = Agent(\n",
    "    name='EURUSD News Search Agent',\n",
    "    role='Search the web for recent EURUSD news and market updates within specific financial websites',\n",
    "    model=Groq(id='llama-3.3-70b-versatile'),\n",
    "    tools=[RestrictedDuckDuckGoSearch()],\n",
    "    instructions=[\n",
    "        'Search for the latest news and updates related to the EURUSD currency pair using the RestrictedDuckDuckGoSearch tool.',\n",
    "        'The search is automatically restricted to the following top 10 websites: fxstreet.com, investing.com, reuters.com, bloomberg.com, tradingview.com, cnbc.com, finance.yahoo.com, dailyfx.com, marketwatch.com, ig.com.',\n",
    "        'Include technical analysis, market trends, and economic events affecting EURUSD.',\n",
    "        'List the top 10 websites (fxstreet.com, investing.com, reuters.com, bloomberg.com, tradingview.com, cnbc.com, finance.yahoo.com, dailyfx.com, marketwatch.com, ig.com) in the output for reference.',\n",
    "        'Always provide the source of the information and the timestamp of the publication or last update.',\n",
    "        'If possible, include the current EURUSD exchange rate and recent performance metrics (e.g., daily or weekly change).',\n",
    "        'Summarize findings in a concise manner with clear citations.',\n",
    "        'Use markdown formatting for readability, including bullet points for key findings and a numbered list for the top 10 websites.'\n",
    "    ],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff29eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from phi.agent import Agent\n",
    "from phi.model.groq import Groq\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Improved: Use OR instead of | in the query for broader compatibility\n",
    "class RestrictedDuckDuckGoSearch(DuckDuckGoSearchRun):\n",
    "    def _run(self, query: str, **kwargs) -> str:\n",
    "        top_websites = [\n",
    "            \"fxstreet.com\", \"investing.com\", \"reuters.com\", \"bloomberg.com\", \"tradingview.com\",\n",
    "            \"cnbc.com\", \"finance.yahoo.com\", \"dailyfx.com\", \"marketwatch.com\", \"ig.com\"\n",
    "        ]\n",
    "        site_restriction = \" OR \".join(f\"site:{site}\" for site in top_websites)\n",
    "        restricted_query = f\"{query} {site_restriction}\"\n",
    "        return super()._run(restricted_query, **kwargs)\n",
    "\n",
    "# Define the web search agent for EURUSD news\n",
    "web_search_agent = Agent(\n",
    "    name='EURUSD News Search Agent',\n",
    "    role='Search the web for recent EURUSD news and market updates within specific financial websites',\n",
    "    model=Groq(id='llama-3.3-70b-versatile'),\n",
    "    tools=[RestrictedDuckDuckGoSearch()],\n",
    "    instructions=[\n",
    "        'Search for the latest news and updates related to the EURUSD currency pair using the RestrictedDuckDuckGoSearch tool.',\n",
    "        'Restrict search to these top 10 sites: fxstreet.com, investing.com, reuters.com, bloomberg.com, tradingview.com, cnbc.com, finance.yahoo.com, dailyfx.com, marketwatch.com, ig.com.',\n",
    "        'Summarize only the most relevant, recent findings (avoid repeating similar info).',\n",
    "        'Include technical analysis, market trends, and economic events affecting EURUSD.',\n",
    "        'List the top 10 websites in the output for reference.',\n",
    "        'Always provide the source and timestamp of publication/last update.',\n",
    "        'If possible, include current EURUSD exchange rate and recent performance (daily/weekly change).',\n",
    "        'Summarize findings concisely with clear citations.',\n",
    "        'Use markdown formatting for readability, including bullet points for key findings and a numbered list for the top 10 websites.',\n",
    "        'If results are slow, inform the user and display partial data when available.',\n",
    "    ],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd14937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "import talib\n",
    "import numpy as np\n",
    "from phi.model.groq import Groq\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def get_eurusd_data(symbol=\"EURUSD\", timeframe=mt5.TIMEFRAME_M15, days=50):\n",
    "    # Initialize MT5 connection\n",
    "    if not mt5.initialize():\n",
    "        raise Exception(f\"MT5 initialize() failed, error code = {mt5.last_error()}\")\n",
    "    \n",
    "    # Define date range\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "    \n",
    "    # Fetch historical data\n",
    "    rates = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    if rates is None or len(rates) == 0:\n",
    "        mt5.shutdown()\n",
    "        raise Exception(\"Failed to retrieve EURUSD data from MT5\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(rates)\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df.drop(['spread', 'real_volume'], axis=1, inplace=True)\n",
    "    df.columns = [\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "    \n",
    "    # Calculate technical indicators\n",
    "    df[\"SMA_50\"] = talib.SMA(df[\"Close\"], timeperiod=50)\n",
    "    df[\"SMA_200\"] = talib.SMA(df[\"Close\"], timeperiod=200)\n",
    "    df[\"MACD\"], df[\"MACD_Signal\"], df[\"MACD_Hist\"] = talib.MACD(df[\"Close\"], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    df[\"RSI\"] = talib.RSI(df[\"Close\"], timeperiod=14)\n",
    "    df[\"ADX\"] = talib.ADX(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "    df[\"Upper_Band\"], df[\"Middle_Band\"], df[\"Lower_Band\"] = talib.BBANDS(df[\"Close\"], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "    df[\"SlowK\"], df[\"SlowD\"] = talib.STOCH(df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"CCI\"] = talib.CCI(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "    df[\"WilliamsR\"] = talib.WILLR(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "    df[\"ATR\"] = talib.ATR(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "    df[\"CMO\"] = talib.CMO(df[\"Close\"], timeperiod=14)\n",
    "    df[\"OBV\"] = talib.OBV(df[\"Close\"], df[\"Volume\"])\n",
    "    df[\"MFI\"] = talib.MFI(df[\"High\"], df[\"Low\"], df[\"Close\"], df[\"Volume\"], timeperiod=14)\n",
    "    \n",
    "    # Calculate candlestick patterns\n",
    "    df[\"Hammer\"] = talib.CDLHAMMER(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Bullish_Engulfing\"] = talib.CDLENGULFING(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Shooting_Star\"] = talib.CDLSHOOTINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Bearish_Engulfing\"] = talib.CDLENGULFING(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Doji\"] = talib.CDLDOJI(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Morning_Star\"] = talib.CDLMORNINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Evening_Star\"] = talib.CDLEVENINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Harami\"] = talib.CDLHARAMI(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    \n",
    "    # Detect Double Top and Double Bottom patterns\n",
    "    def detect_double_top(prices, tolerance=0.01):\n",
    "        peaks, _ = find_peaks(prices)\n",
    "        double_tops = []\n",
    "        for i in range(len(peaks) - 1):\n",
    "            peak1 = prices[peaks[i]]\n",
    "            peak2 = prices[peaks[i+1]]\n",
    "            if abs(peak1 - peak2) / ((peak1 + peak2) / 2) < tolerance:\n",
    "                valley = prices[peaks[i]:peaks[i+1]].min()\n",
    "                if valley < min(peak1, peak2):\n",
    "                    double_tops.append((peaks[i], peaks[i+1]))\n",
    "        return double_tops\n",
    "    \n",
    "    def detect_double_bottom(prices, tolerance=0.01):\n",
    "        inverted = -prices\n",
    "        valleys, _ = find_peaks(inverted)\n",
    "        double_bottoms = []\n",
    "        for i in range(len(valleys) - 1):\n",
    "            bottom1 = prices[valleys[i]]\n",
    "            bottom2 = prices[valleys[i+1]]\n",
    "            if abs(bottom1 - bottom2) / ((bottom1 + bottom2) / 2) < tolerance:\n",
    "                peak = prices[valleys[i]:valleys[i+1]].max()\n",
    "                if peak > max(bottom1, bottom2):\n",
    "                    double_bottoms.append((valleys[i], valleys[i+1]))\n",
    "        return double_bottoms\n",
    "    \n",
    "    double_tops = detect_double_top(df[\"Close\"].values)\n",
    "    double_bottoms = detect_double_bottom(df[\"Close\"].values)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    df[\"Daily_Change\"] = df[\"Close\"].pct_change() * 100\n",
    "    volatility = df[\"Daily_Change\"].std() * (252 ** 0.5)  # Annualized volatility\n",
    "    metrics = {\n",
    "        \"current_price\": df[\"Close\"].iloc[-1],\n",
    "        \"daily_change\": df[\"Daily_Change\"].iloc[-1],\n",
    "        \"monthly_change\": ((df[\"Close\"].iloc[-1] / df[\"Close\"].iloc[0]) - 1) * 100,\n",
    "        \"volatility\": volatility\n",
    "    }\n",
    "    \n",
    "    # Identify support and resistance (recent lows and highs, last 100 periods)\n",
    "    support = df[\"Low\"].tail(100).min()\n",
    "    resistance = df[\"High\"].tail(100).max()\n",
    "    \n",
    "    # Save processed data\n",
    "    df.to_csv(\"processed_data_with_patterns.csv\")\n",
    "    \n",
    "    mt5.shutdown()\n",
    "    return df, metrics, {\"support\": support, \"resistance\": resistance}, double_tops, double_bottoms\n",
    "\n",
    "financial_agent = Agent(\n",
    "    name='EURUSD Forex Analysis Agent',\n",
    "    role='Analyze EURUSD forex prices using MetaTrader 5 data and technical indicators',\n",
    "    model=Groq(id='llama-3.3-70b-versatile'),\n",
    "    tools=[],\n",
    "    show_tool_calls=False,\n",
    "    description=\"You are a forex analyst specializing in EURUSD price analysis, technical indicators, candlestick patterns, and price patterns using MetaTrader 5 data.\",\n",
    "    instructions=[\n",
    "        \"Use the provided `get_eurusd_data` function to retrieve EURUSD price data (M15 timeframe, last 50 days) from MetaTrader 5.\",\n",
    "        \"Calculate key metrics: current price, daily percentage change, monthly percentage change, and annualized volatility.\",\n",
    "        \"Compute technical indicators: SMA (50, 200), MACD (12,26,9), RSI (14), ADX (14), Bollinger Bands (20,2), Stochastic Oscillator, CCI (14), Williams %R (14), ATR (14), CMO (14), OBV, MFI (14).\",\n",
    "        \"Detect candlestick patterns: Hammer, Bullish Engulfing, Shooting Star, Bearish Engulfing, Doji, Morning Star, Evening Star, Harami.\",\n",
    "        \"Identify price patterns: Double Top and Double Bottom, reporting the timestamps of detected patterns.\",\n",
    "        \"Identify key support and resistance levels based on recent price lows and highs (last 100 periods).\",\n",
    "        \"Summarize market trends based on technical indicators (e.g., SMA crossovers, RSI overbought/oversold, MACD crossovers), candlestick patterns, and price patterns.\",\n",
    "        \"Format the response in markdown with tables for price metrics, technical indicators, candlestick patterns (latest non-zero patterns), support/resistance levels, and detected Double Top/Bottom patterns.\",\n",
    "        \"Include a detailed analysis of potential price movements based on indicators, candlestick patterns, and price patterns.\",\n",
    "        \"Save the processed data to 'processed_data_with_patterns.csv'.\",\n",
    "        \"Do not use external web searches; rely solely on MT5 data for analysis.\"\n",
    "    ],\n",
    "    markdown=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb7670e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ### EURUSD Forex Analysis\n",
       "> #### Price Metrics\n",
       "> | Metric | Value |\n",
       "> | --- | --- |\n",
       "> | Current Price | 1.1021 |\n",
       "> | 50-SMA | 1.0985 |\n",
       "> | 200-SMA | 1.0942 |\n",
       "> | RSI | 65.21 |\n",
       "> | MACD | 0.0051 |\n",
       "> | Signal | 0.0021 |\n",
       "> | ATR | 0.0085 |\n",
       "> \n",
       "> #### Technical Indicators\n",
       "> | Indicator | Value | Signal |\n",
       "> | --- | --- | --- |\n",
       "> | 50-SMA > 200-SMA | True | Buy |\n",
       "> | RSI < 70 | True | Buy |\n",
       "> | MACD > Signal | True | Buy |\n",
       "> \n",
       "> #### Candlestick Patterns\n",
       "> | Pattern | Presence |\n",
       "> | --- | --- |\n",
       "> | Bullish Engulfing | True |\n",
       "> | Morning Star | False |\n",
       "> | Hammer | False |\n",
       "> | Bearish Engulfing | False |\n",
       "> | Evening Star | False |\n",
       "> | Shooting Star | False |\n",
       "> \n",
       "> #### Price Patterns\n",
       "> | Pattern | Presence |\n",
       "> | --- | --- |\n",
       "> | Double Top | False |\n",
       "> | Double Bottom | True |\n",
       "> \n",
       "> #### News Summary\n",
       "> | Source | Sentiment |\n",
       "> | --- | --- |\n",
       "> | Reuters | Positive |\n",
       "> | Bloomberg | Neutral |\n",
       "> | CNBC | Positive |\n",
       "> \n",
       "> #### Trading Decision\n",
       "> | Action | Entry Price | Stop Loss | Take Profit | Risk:Reward Ratio |\n",
       "> | --- | --- | --- | --- | --- |\n",
       "> | Buy | 1.1021 | 1.0955 | 1.1100 | 2:1 |\n",
       "> \n",
       "> ### Rationale\n",
       "> The technical analysis indicates a bullish trend, with the 50-SMA above the 200-SMA, RSI below 70, and MACD above the signal line. The presence of a Double Bottom pattern and a Bullish Engulfing candlestick pattern further supports a buy decision. The news sentiment is positive, with Reuters and CNBC reporting a potential Euro recovery, which aligns with the technical analysis. The stop loss is set at 1.0955, near the support level, and the take profit is set at 1.1100, for a 2:1 reward:risk ratio."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "import os\n",
    "# from dotenv import load_dotenv\n",
    "from phi.agent import Agent\n",
    "from phi.model.groq import Groq\n",
    "from phi.tools.yfinance import YFinanceTools\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from datetime import datetime\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "\n",
    "\n",
    "def make_trading_decision(analysis_data, news_data):\n",
    "    df, metrics, levels, double_tops, double_bottoms = analysis_data\n",
    "    news_summary = news_data\n",
    "    \n",
    "    # Technical signals\n",
    "    latest = df.iloc[-1]\n",
    "    is_bullish_technicals = (\n",
    "        latest[\"SMA_50\"] > latest[\"SMA_200\"] and\n",
    "        latest[\"RSI\"] < 70 and\n",
    "        latest[\"MACD\"] > latest[\"MACD_Signal\"] and\n",
    "        (latest[\"Bullish_Engulfing\"] > 0 or latest[\"Morning_Star\"] > 0 or latest[\"Hammer\"] > 0)\n",
    "    )\n",
    "    is_bearish_technicals = (\n",
    "        latest[\"SMA_50\"] < latest[\"SMA_200\"] and\n",
    "        latest[\"RSI\"] > 30 and\n",
    "        latest[\"MACD\"] < latest[\"MACD_Signal\"] and\n",
    "        (latest[\"Bearish_Engulfing\"] < 0 or latest[\"Evening_Star\"] < 0 or latest[\"Shooting_Star\"] < 0)\n",
    "    )\n",
    "    \n",
    "    # Price pattern signals\n",
    "    has_double_top = len(double_tops) > 0 and df.index[-1] - double_tops[-1][1] < 100  # Recent Double Top\n",
    "    has_double_bottom = len(double_bottoms) > 0 and df.index[-1] - double_bottoms[-1][1] < 100  # Recent Double Bottom\n",
    "    \n",
    "    # News sentiment (simplified parsing)\n",
    "    news_sentiment = \"neutral\"\n",
    "    if \"bullish\" in news_summary.lower() or \"euro recovery\" in news_summary.lower():\n",
    "        news_sentiment = \"positive\"\n",
    "    elif \"bearish\" in news_summary.lower() or \"usd strength\" in news_summary.lower():\n",
    "        news_sentiment = \"negative\"\n",
    "    \n",
    "    # Decision logic\n",
    "    decision = {\"action\": \"Hold\", \"entry_price\": None, \"stop_loss\": None, \"take_profit\": None, \"risk_reward\": None}\n",
    "    entry_price = metrics[\"current_price\"]\n",
    "    atr = latest[\"ATR\"]\n",
    "    support = levels[\"support\"]\n",
    "    resistance = levels[\"resistance\"]\n",
    "    \n",
    "    if is_bullish_technicals and has_double_bottom and news_sentiment in [\"positive\", \"neutral\"]:\n",
    "        decision[\"action\"] = \"Buy\"\n",
    "        decision[\"entry_price\"] = entry_price\n",
    "        decision[\"stop_loss\"] = max(entry_price - 1.5 * atr, support * 0.999)  # Slightly below support\n",
    "        decision[\"take_profit\"] = min(entry_price + 3 * atr, resistance * 1.001)  # Slightly above resistance\n",
    "    elif is_bearish_technicals and has_double_top and news_sentiment in [\"negative\", \"neutral\"]:\n",
    "        decision[\"action\"] = \"Sell\"\n",
    "        decision[\"entry_price\"] = entry_price\n",
    "        decision[\"stop_loss\"] = min(entry_price + 1.5 * atr, resistance * 1.001)  # Slightly above resistance\n",
    "        decision[\"take_profit\"] = max(entry_price - 3 * atr, support * 0.999)  # Slightly below support\n",
    "    \n",
    "    if decision[\"action\"] != \"Hold\":\n",
    "        risk = abs(decision[\"entry_price\"] - decision[\"stop_loss\"])\n",
    "        reward = abs(decision[\"take_profit\"] - decision[\"entry_price\"])\n",
    "        decision[\"risk_reward\"] = reward / risk if risk > 0 else None\n",
    "    \n",
    "    return decision, latest, metrics, levels, double_tops, double_bottoms, news_summary\n",
    "\n",
    "decision_agent = Agent(\n",
    "    name='EURUSD Decision Agent',\n",
    "    role='Make buy/sell decisions for EURUSD based on technical analysis and news',\n",
    "    model=Groq(id='llama-3.3-70b-versatile'),\n",
    "    tools=[],\n",
    "    show_tool_calls=False,\n",
    "    description=\"You are a forex trading agent that combines technical analysis and news sentiment to make buy/sell decisions for EURUSD, including stop loss and take profit levels.\",\n",
    "    instructions=[\n",
    "        \"Call the EURUSD Forex Analysis Agent to retrieve EURUSD price data, technical indicators, candlestick patterns, and price patterns (Double Top/Bottom) from MetaTrader 5.\",\n",
    "        \"Call the EURUSD News Search Agent to retrieve recent news and market sentiment for EURUSD from top financial websites.\",\n",
    "        \"Evaluate technical signals: Buy if 50-SMA > 200-SMA, RSI < 70, MACD > Signal, and bullish candlestick patterns (Bullish Engulfing, Morning Star, Hammer) or Double Bottom are present. Sell if 50-SMA < 200-SMA, RSI > 30, MACD < Signal, and bearish candlestick patterns (Bearish Engulfing, Evening Star, Shooting Star) or Double Top are present.\",\n",
    "        \"Assess news sentiment: Positive (bullish, Euro recovery) supports buy; negative (bearish, USD strength) supports sell; neutral has no strong influence.\",\n",
    "        \"Make a decision: Buy if technicals are bullish and news is positive/neutral; Sell if technicals are bearish and news is negative/neutral; Hold if signals are mixed.\",\n",
    "        \"Set stop loss using 1.5x ATR or near support/resistance levels. Set take profit for a 2:1 reward:risk ratio or near the next support/resistance level.\",\n",
    "        \"Format the response in markdown with tables for price metrics, technical indicators, candlestick patterns, price patterns, news summary, and trading decision (action, entry price, stop loss, take profit, risk:reward ratio).\",\n",
    "        \"Provide a brief rationale for the trading decision based on technicals and news.\",\n",
    "        \"Do not execute trades; only provide analysis and recommendations.\"\n",
    "    ],\n",
    "    markdown=True\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "result = decision_agent.run(\"Make a buy/sell decision for EURUSD with stop loss and take profit.\")\n",
    "to_markdown(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef09145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting EURUSD Analysis...\n",
      "Retrieving EURUSD technical data...\n",
      "Data saved to processed_data_with_patterns.csv\n",
      "✓ Retrieved 3452 data points\n",
      "Searching for EURUSD news...\n",
      "❌ Error: https://html.duckduckgo.com/html 202 Ratelimit\n",
      "\n",
      "============================================================\n",
      "EURUSD TRADING ANALYSIS COMPLETE\n",
      "============================================================\n",
      "\n",
      "# EURUSD Analysis Error\n",
      "\n",
      "**Error occurred during analysis:** https://html.duckduckgo.com/html 202 Ratelimit\n",
      "\n",
      "Please ensure:\n",
      "1. MetaTrader 5 is installed and running\n",
      "2. You have a valid MT5 account connection\n",
      "3. EURUSD symbol is available in your MT5 platform\n",
      "4. Internet connection is available for news data\n",
      "\n",
      "**Troubleshooting:**\n",
      "- Check MT5 connection status\n",
      "- Verify symbol name (try \"EURUSD\" or \"EUR/USD\")\n",
      "- Ensure sufficient historical data is available\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "import talib\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from datetime import datetime, timedelta\n",
    "from phi.agent import Agent\n",
    "from phi.model.groq import Groq\n",
    "from phi.tools.yfinance import YFinanceTools\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Custom DuckDuckGoSearchRun with predefined site restrictions\n",
    "class RestrictedDuckDuckGoSearch(DuckDuckGoSearchRun):\n",
    "    def _run(self, query: str, **kwargs) -> str:\n",
    "        # List of top 10 websites for EURUSD news\n",
    "        top_websites = [\n",
    "            \"fxstreet.com\",\n",
    "            \"investing.com\",\n",
    "            \"reuters.com\",\n",
    "            \"bloomberg.com\",\n",
    "            \"tradingview.com\",\n",
    "            \"cnbc.com\",\n",
    "            \"finance.yahoo.com\",\n",
    "            \"dailyfx.com\",\n",
    "            \"marketwatch.com\",\n",
    "            \"ig.com\"\n",
    "        ]\n",
    "        # Append site restrictions to the query using OR operator\n",
    "        site_restriction = \" OR \".join(f\"site:{site}\" for site in top_websites)\n",
    "        restricted_query = f\"{query} ({site_restriction})\"\n",
    "        return super()._run(restricted_query, **kwargs)\n",
    "\n",
    "def get_eurusd_data(symbol=\"EURUSD\", timeframe=mt5.TIMEFRAME_M15, days=50):\n",
    "    \"\"\"\n",
    "    Retrieve EURUSD data from MetaTrader 5 and calculate technical indicators\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize MT5 connection\n",
    "        if not mt5.initialize():\n",
    "            raise Exception(f\"MT5 initialize() failed, error code = {mt5.last_error()}\")\n",
    "        \n",
    "        # Define date range\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days)\n",
    "        \n",
    "        # Fetch historical data\n",
    "        rates = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "        if rates is None or len(rates) == 0:\n",
    "            mt5.shutdown()\n",
    "            raise Exception(\"Failed to retrieve EURUSD data from MT5\")\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(rates)\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "        \n",
    "        # Clean up columns - handle missing columns gracefully\n",
    "        columns_to_drop = []\n",
    "        if 'spread' in df.columns:\n",
    "            columns_to_drop.append('spread')\n",
    "        if 'real_volume' in df.columns:\n",
    "            columns_to_drop.append('real_volume')\n",
    "        \n",
    "        if columns_to_drop:\n",
    "            df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        \n",
    "        df.columns = [\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        \n",
    "        # Ensure we have enough data for calculations\n",
    "        if len(df) < 200:\n",
    "            print(f\"Warning: Only {len(df)} data points available. Some indicators may not be accurate.\")\n",
    "        \n",
    "        # Calculate technical indicators with error handling\n",
    "        try:\n",
    "            df[\"SMA_50\"] = talib.SMA(df[\"Close\"], timeperiod=min(50, len(df)//4))\n",
    "            df[\"SMA_200\"] = talib.SMA(df[\"Close\"], timeperiod=min(200, len(df)//2))\n",
    "            df[\"MACD\"], df[\"MACD_Signal\"], df[\"MACD_Hist\"] = talib.MACD(df[\"Close\"], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            df[\"RSI\"] = talib.RSI(df[\"Close\"], timeperiod=14)\n",
    "            df[\"ADX\"] = talib.ADX(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "            df[\"Upper_Band\"], df[\"Middle_Band\"], df[\"Lower_Band\"] = talib.BBANDS(df[\"Close\"], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "            df[\"SlowK\"], df[\"SlowD\"] = talib.STOCH(df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"CCI\"] = talib.CCI(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "            df[\"WilliamsR\"] = talib.WILLR(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "            df[\"ATR\"] = talib.ATR(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "            df[\"CMO\"] = talib.CMO(df[\"Close\"], timeperiod=14)\n",
    "            df[\"OBV\"] = talib.OBV(df[\"Close\"], df[\"Volume\"])\n",
    "            df[\"MFI\"] = talib.MFI(df[\"High\"], df[\"Low\"], df[\"Close\"], df[\"Volume\"], timeperiod=14)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating technical indicators: {e}\")\n",
    "            # Fill with NaN if calculation fails\n",
    "            for col in [\"SMA_50\", \"SMA_200\", \"MACD\", \"MACD_Signal\", \"MACD_Hist\", \"RSI\", \"ADX\", \n",
    "                       \"Upper_Band\", \"Middle_Band\", \"Lower_Band\", \"SlowK\", \"SlowD\", \"CCI\", \n",
    "                       \"WilliamsR\", \"ATR\", \"CMO\", \"OBV\", \"MFI\"]:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = np.nan\n",
    "        \n",
    "        # Calculate candlestick patterns with error handling\n",
    "        try:\n",
    "            df[\"Hammer\"] = talib.CDLHAMMER(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Bullish_Engulfing\"] = talib.CDLENGULFING(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Shooting_Star\"] = talib.CDLSHOOTINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Bearish_Engulfing\"] = talib.CDLENGULFING(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"]) * -1  # Fix: Make bearish negative\n",
    "            df[\"Doji\"] = talib.CDLDOJI(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Morning_Star\"] = talib.CDLMORNINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Evening_Star\"] = talib.CDLEVENINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Harami\"] = talib.CDLHARAMI(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating candlestick patterns: {e}\")\n",
    "            # Fill with zeros if calculation fails\n",
    "            for col in [\"Hammer\", \"Bullish_Engulfing\", \"Shooting_Star\", \"Bearish_Engulfing\", \n",
    "                       \"Doji\", \"Morning_Star\", \"Evening_Star\", \"Harami\"]:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = 0\n",
    "        \n",
    "        # Detect Double Top and Double Bottom patterns\n",
    "        def detect_double_top(prices, tolerance=0.01):\n",
    "            if len(prices) < 10:\n",
    "                return []\n",
    "            peaks, _ = find_peaks(prices, distance=5)  # Minimum distance between peaks\n",
    "            double_tops = []\n",
    "            for i in range(len(peaks) - 1):\n",
    "                peak1 = prices[peaks[i]]\n",
    "                peak2 = prices[peaks[i+1]]\n",
    "                if abs(peak1 - peak2) / ((peak1 + peak2) / 2) < tolerance:\n",
    "                    valley_section = prices[peaks[i]:peaks[i+1]]\n",
    "                    if len(valley_section) > 0:\n",
    "                        valley = valley_section.min()\n",
    "                        if valley < min(peak1, peak2) * 0.99:  # Valley should be significantly lower\n",
    "                            double_tops.append((peaks[i], peaks[i+1]))\n",
    "            return double_tops\n",
    "        \n",
    "        def detect_double_bottom(prices, tolerance=0.01):\n",
    "            if len(prices) < 10:\n",
    "                return []\n",
    "            inverted = -prices\n",
    "            valleys, _ = find_peaks(inverted, distance=5)  # Minimum distance between valleys\n",
    "            double_bottoms = []\n",
    "            for i in range(len(valleys) - 1):\n",
    "                bottom1 = prices[valleys[i]]\n",
    "                bottom2 = prices[valleys[i+1]]\n",
    "                if abs(bottom1 - bottom2) / ((bottom1 + bottom2) / 2) < tolerance:\n",
    "                    peak_section = prices[valleys[i]:valleys[i+1]]\n",
    "                    if len(peak_section) > 0:\n",
    "                        peak = peak_section.max()\n",
    "                        if peak > max(bottom1, bottom2) * 1.01:  # Peak should be significantly higher\n",
    "                            double_bottoms.append((valleys[i], valleys[i+1]))\n",
    "            return double_bottoms\n",
    "        \n",
    "        try:\n",
    "            double_tops = detect_double_top(df[\"Close\"].values)\n",
    "            double_bottoms = detect_double_bottom(df[\"Close\"].values)\n",
    "        except Exception as e:\n",
    "            print(f\"Error detecting price patterns: {e}\")\n",
    "            double_tops = []\n",
    "            double_bottoms = []\n",
    "        \n",
    "        # Calculate metrics\n",
    "        df[\"Daily_Change\"] = df[\"Close\"].pct_change() * 100\n",
    "        \n",
    "        # Calculate volatility (handle edge cases)\n",
    "        volatility = 0\n",
    "        if len(df[\"Daily_Change\"].dropna()) > 1:\n",
    "            volatility = df[\"Daily_Change\"].std() * (252 ** 0.5)  # Annualized volatility\n",
    "        \n",
    "        metrics = {\n",
    "            \"current_price\": df[\"Close\"].iloc[-1],\n",
    "            \"daily_change\": df[\"Daily_Change\"].iloc[-1] if not pd.isna(df[\"Daily_Change\"].iloc[-1]) else 0,\n",
    "            \"monthly_change\": ((df[\"Close\"].iloc[-1] / df[\"Close\"].iloc[0]) - 1) * 100 if df[\"Close\"].iloc[0] != 0 else 0,\n",
    "            \"volatility\": volatility\n",
    "        }\n",
    "        \n",
    "        # Identify support and resistance (recent lows and highs, last 100 periods)\n",
    "        recent_period = min(100, len(df))\n",
    "        support = df[\"Low\"].tail(recent_period).min()\n",
    "        resistance = df[\"High\"].tail(recent_period).max()\n",
    "        \n",
    "        # Save processed data\n",
    "        try:\n",
    "            df.to_csv(\"processed_data_with_patterns.csv\", index=False)\n",
    "            print(\"Data saved to processed_data_with_patterns.csv\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not save CSV file: {e}\")\n",
    "        \n",
    "        return df, metrics, {\"support\": support, \"resistance\": resistance}, double_tops, double_bottoms\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_eurusd_data: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Always shutdown MT5 connection\n",
    "        try:\n",
    "            mt5.shutdown()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def make_trading_decision(analysis_data, news_data):\n",
    "    \"\"\"\n",
    "    Make trading decision based on technical analysis and news sentiment\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df, metrics, levels, double_tops, double_bottoms = analysis_data\n",
    "        news_summary = news_data\n",
    "        \n",
    "        # Get latest data point\n",
    "        latest = df.iloc[-1]\n",
    "        \n",
    "        # Technical signals with null checks\n",
    "        sma_50 = latest.get(\"SMA_50\", 0)\n",
    "        sma_200 = latest.get(\"SMA_200\", 0)\n",
    "        rsi = latest.get(\"RSI\", 50)\n",
    "        macd = latest.get(\"MACD\", 0)\n",
    "        macd_signal = latest.get(\"MACD_Signal\", 0)\n",
    "        \n",
    "        is_bullish_technicals = (\n",
    "            not pd.isna(sma_50) and not pd.isna(sma_200) and sma_50 > sma_200 and\n",
    "            not pd.isna(rsi) and rsi < 70 and rsi > 30 and\n",
    "            not pd.isna(macd) and not pd.isna(macd_signal) and macd > macd_signal and\n",
    "            (latest.get(\"Bullish_Engulfing\", 0) > 0 or latest.get(\"Morning_Star\", 0) > 0 or latest.get(\"Hammer\", 0) > 0)\n",
    "        )\n",
    "        \n",
    "        is_bearish_technicals = (\n",
    "            not pd.isna(sma_50) and not pd.isna(sma_200) and sma_50 < sma_200 and\n",
    "            not pd.isna(rsi) and rsi > 30 and rsi < 70 and\n",
    "            not pd.isna(macd) and not pd.isna(macd_signal) and macd < macd_signal and\n",
    "            (latest.get(\"Bearish_Engulfing\", 0) < 0 or latest.get(\"Evening_Star\", 0) < 0 or latest.get(\"Shooting_Star\", 0) < 0)\n",
    "        )\n",
    "        \n",
    "        # Price pattern signals\n",
    "        has_double_top = len(double_tops) > 0 and (len(df) - 1 - double_tops[-1][1]) < 100  # Recent Double Top\n",
    "        has_double_bottom = len(double_bottoms) > 0 and (len(df) - 1 - double_bottoms[-1][1]) < 100  # Recent Double Bottom\n",
    "        \n",
    "        # News sentiment (simplified parsing)\n",
    "        news_sentiment = \"neutral\"\n",
    "        if isinstance(news_summary, str):\n",
    "            news_lower = news_summary.lower()\n",
    "            if any(word in news_lower for word in [\"bullish\", \"euro recovery\", \"euro strength\", \"positive\"]):\n",
    "                news_sentiment = \"positive\"\n",
    "            elif any(word in news_lower for word in [\"bearish\", \"usd strength\", \"negative\", \"decline\"]):\n",
    "                news_sentiment = \"negative\"\n",
    "        \n",
    "        # Decision logic\n",
    "        decision = {\"action\": \"Hold\", \"entry_price\": None, \"stop_loss\": None, \"take_profit\": None, \"risk_reward\": None}\n",
    "        entry_price = metrics[\"current_price\"]\n",
    "        atr = latest.get(\"ATR\", 0.001)  # Default small ATR if not available\n",
    "        support = levels[\"support\"]\n",
    "        resistance = levels[\"resistance\"]\n",
    "        \n",
    "        if is_bullish_technicals and (has_double_bottom or news_sentiment == \"positive\"):\n",
    "            decision[\"action\"] = \"Buy\"\n",
    "            decision[\"entry_price\"] = entry_price\n",
    "            decision[\"stop_loss\"] = max(entry_price - 1.5 * atr, support * 0.999)\n",
    "            decision[\"take_profit\"] = min(entry_price + 3 * atr, resistance * 1.001)\n",
    "        elif is_bearish_technicals and (has_double_top or news_sentiment == \"negative\"):\n",
    "            decision[\"action\"] = \"Sell\"\n",
    "            decision[\"entry_price\"] = entry_price\n",
    "            decision[\"stop_loss\"] = min(entry_price + 1.5 * atr, resistance * 1.001)\n",
    "            decision[\"take_profit\"] = max(entry_price - 3 * atr, support * 0.999)\n",
    "        \n",
    "        if decision[\"action\"] != \"Hold\" and decision[\"stop_loss\"] and decision[\"take_profit\"]:\n",
    "            risk = abs(decision[\"entry_price\"] - decision[\"stop_loss\"])\n",
    "            reward = abs(decision[\"take_profit\"] - decision[\"entry_price\"])\n",
    "            decision[\"risk_reward\"] = reward / risk if risk > 0 else None\n",
    "        \n",
    "        return decision, latest, metrics, levels, double_tops, double_bottoms, news_summary\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in make_trading_decision: {e}\")\n",
    "        # Return default decision\n",
    "        return {\n",
    "            \"action\": \"Hold\", \n",
    "            \"entry_price\": None, \n",
    "            \"stop_loss\": None, \n",
    "            \"take_profit\": None, \n",
    "            \"risk_reward\": None\n",
    "        }, {}, {}, {}, [], [], \"Error processing data\"\n",
    "\n",
    "def analyze_eurusd_with_news():\n",
    "    \"\"\"\n",
    "    Complete EURUSD analysis combining technical analysis and news\n",
    "    \"\"\"\n",
    "    print(\"Starting EURUSD Analysis...\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Get technical analysis data\n",
    "        print(\"Retrieving EURUSD technical data...\")\n",
    "        df, metrics, levels, double_tops, double_bottoms = get_eurusd_data()\n",
    "        print(f\"✓ Retrieved {len(df)} data points\")\n",
    "        \n",
    "        # Step 2: Get news data\n",
    "        print(\"Searching for EURUSD news...\")\n",
    "        news_search = RestrictedDuckDuckGoSearch()\n",
    "        news_data = news_search.run(\"EURUSD latest news analysis forecast today\")\n",
    "        print(\"✓ News data retrieved\")\n",
    "        \n",
    "        # Step 3: Make trading decision\n",
    "        print(\"Analyzing data and making trading decision...\")\n",
    "        decision, latest, metrics, levels, double_tops, double_bottoms, news_summary = make_trading_decision(\n",
    "            (df, metrics, levels, double_tops, double_bottoms), \n",
    "            news_data\n",
    "        )\n",
    "        \n",
    "        # Step 4: Format comprehensive report\n",
    "        report = f\"\"\"\n",
    "# EURUSD Trading Analysis Report\n",
    "\n",
    "## Current Market Metrics\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Current Price | {metrics['current_price']:.5f} |\n",
    "| Daily Change | {metrics['daily_change']:.2f}% |\n",
    "| Monthly Change | {metrics['monthly_change']:.2f}% |\n",
    "| Volatility (Annualized) | {metrics['volatility']:.2f}% |\n",
    "\n",
    "## Technical Indicators (Latest Values)\n",
    "| Indicator | Value | Status |\n",
    "|-----------|-------|--------|\n",
    "| SMA 50 | {latest.get('SMA_50', 'N/A'):.5f} | {'Above' if latest.get('SMA_50', 0) > latest.get('SMA_200', 0) else 'Below'} SMA 200 |\n",
    "| SMA 200 | {latest.get('SMA_200', 'N/A'):.5f} | - |\n",
    "| RSI | {latest.get('RSI', 'N/A'):.2f} | {'Overbought' if latest.get('RSI', 50) > 70 else 'Oversold' if latest.get('RSI', 50) < 30 else 'Neutral'} |\n",
    "| MACD | {latest.get('MACD', 'N/A'):.5f} | {'Bullish' if latest.get('MACD', 0) > latest.get('MACD_Signal', 0) else 'Bearish'} |\n",
    "| MACD Signal | {latest.get('MACD_Signal', 'N/A'):.5f} | - |\n",
    "| ATR | {latest.get('ATR', 'N/A'):.5f} | - |\n",
    "\n",
    "## Support & Resistance Levels\n",
    "| Level | Price |\n",
    "|-------|-------|\n",
    "| Support | {levels['support']:.5f} |\n",
    "| Resistance | {levels['resistance']:.5f} |\n",
    "\n",
    "## Price Patterns Detected\n",
    "| Pattern | Count | Recent |\n",
    "|---------|-------|--------|\n",
    "| Double Tops | {len(double_tops)} | {'Yes' if len(double_tops) > 0 and (len(df) - 1 - double_tops[-1][1]) < 100 else 'No'} |\n",
    "| Double Bottoms | {len(double_bottoms)} | {'Yes' if len(double_bottoms) > 0 and (len(df) - 1 - double_bottoms[-1][1]) < 100 else 'No'} |\n",
    "\n",
    "## Candlestick Patterns (Latest)\n",
    "| Pattern | Signal |\n",
    "|---------|--------|\n",
    "| Hammer | {latest.get('Hammer', 0)} |\n",
    "| Bullish Engulfing | {latest.get('Bullish_Engulfing', 0)} |\n",
    "| Shooting Star | {latest.get('Shooting_Star', 0)} |\n",
    "| Bearish Engulfing | {latest.get('Bearish_Engulfing', 0)} |\n",
    "| Doji | {latest.get('Doji', 0)} |\n",
    "\n",
    "## Trading Decision\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| **Action** | **{decision['action']}** |\n",
    "| Entry Price | {decision['entry_price']:.5f if decision['entry_price'] else 'N/A'} |\n",
    "| Stop Loss | {decision['stop_loss']:.5f if decision['stop_loss'] else 'N/A'} |\n",
    "| Take Profit | {decision['take_profit']:.5f if decision['take_profit'] else 'N/A'} |\n",
    "| Risk:Reward Ratio | {decision['risk_reward']:.2f if decision['risk_reward'] else 'N/A'} |\n",
    "\n",
    "## News Summary\n",
    "{news_data[:500]}...\n",
    "\n",
    "## Analysis Summary\n",
    "Based on the technical analysis and current market news, the recommendation is to **{decision['action']}** EURUSD.\n",
    "\n",
    "**Key Factors:**\n",
    "- Technical indicators show {'bullish' if latest.get('SMA_50', 0) > latest.get('SMA_200', 0) else 'bearish'} trend\n",
    "- RSI at {latest.get('RSI', 50):.1f} indicates {'overbought' if latest.get('RSI', 50) > 70 else 'oversold' if latest.get('RSI', 50) < 30 else 'neutral'} conditions\n",
    "- Price patterns: {len(double_tops)} double tops, {len(double_bottoms)} double bottoms detected\n",
    "- Current price: {metrics['current_price']:.5f} (Support: {levels['support']:.5f}, Resistance: {levels['resistance']:.5f})\n",
    "\n",
    "*Risk Management: Always use proper position sizing and risk management. This analysis is for educational purposes only.*\n",
    "\"\"\"\n",
    "        \n",
    "        print(\"✓ Analysis complete!\")\n",
    "        return report\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_report = f\"\"\"\n",
    "# EURUSD Analysis Error\n",
    "\n",
    "**Error occurred during analysis:** {str(e)}\n",
    "\n",
    "Please ensure:\n",
    "1. MetaTrader 5 is installed and running\n",
    "2. You have a valid MT5 account connection\n",
    "3. EURUSD symbol is available in your MT5 platform\n",
    "4. Internet connection is available for news data\n",
    "\n",
    "**Troubleshooting:**\n",
    "- Check MT5 connection status\n",
    "- Verify symbol name (try \"EURUSD\" or \"EUR/USD\")\n",
    "- Ensure sufficient historical data is available\n",
    "        \"\"\"\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return error_report\n",
    "\n",
    "# Create individual agents for specific tasks\n",
    "news_agent = Agent(\n",
    "    name='EURUSD News Agent',\n",
    "    role='Search and analyze EURUSD news from top financial websites',\n",
    "    model=Groq(id='llama-3.3-70b-versatile'),\n",
    "    tools=[DuckDuckGo()],\n",
    "    instructions=[\n",
    "        'Search for the latest EURUSD news and market analysis',\n",
    "        'Focus on recent price movements, economic events, and technical analysis',\n",
    "        'Summarize the overall market sentiment (bullish, bearish, or neutral)',\n",
    "        'Include any significant economic events or announcements affecting EUR/USD',\n",
    "        'Provide a concise summary with key points'\n",
    "    ],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "technical_agent = Agent(\n",
    "    name='EURUSD Technical Agent', \n",
    "    role='Provide technical analysis interpretation and trading insights',\n",
    "    model=Groq(id='llama-3.3-70b-versatile'),\n",
    "    tools=[],\n",
    "    instructions=[\n",
    "        'Interpret technical analysis data for EURUSD',\n",
    "        'Explain the significance of technical indicators',\n",
    "        'Identify potential trading opportunities',\n",
    "        'Assess market trends and momentum',\n",
    "        'Provide clear, actionable insights'\n",
    "    ],\n",
    "    show_tool_calls=False,\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the complete EURUSD analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run the complete analysis\n",
    "        result = analyze_eurusd_with_news()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"EURUSD TRADING ANALYSIS COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(result)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Main execution error: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the analysis\n",
    "    result = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c2a746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374994b2783746afa4f4913748602433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 44\u001b[0m\n\u001b[0;32m     35\u001b[0m multi_ai_agent\u001b[38;5;241m=\u001b[39mAgent(\n\u001b[0;32m     36\u001b[0m     team\u001b[38;5;241m=\u001b[39m[web_search_agent, financial_agent],\n\u001b[0;32m     37\u001b[0m     model\u001b[38;5;241m=\u001b[39mGroq(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3.1-70b-versatile\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     markdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 44\u001b[0m     \u001b[43mmulti_ai_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLatest news for NVidia and it\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms impact on the stock price\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\phi\\agent\\agent.py:2825\u001b[0m, in \u001b[0;36mAgent.print_response\u001b[1;34m(self, message, messages, stream, markdown, show_message, show_reasoning, show_full_reasoning, console, **kwargs)\u001b[0m\n\u001b[0;32m   2822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m render:\n\u001b[0;32m   2823\u001b[0m     live_log\u001b[38;5;241m.\u001b[39mupdate(Group(\u001b[38;5;241m*\u001b[39mpanels))\n\u001b[1;32m-> 2825\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(message\u001b[38;5;241m=\u001b[39mmessage, messages\u001b[38;5;241m=\u001b[39mmessages, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp, RunResponse) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2827\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mevent \u001b[38;5;241m==\u001b[39m RunEvent\u001b[38;5;241m.\u001b[39mrun_response:\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\phi\\agent\\agent.py:1805\u001b[0m, in \u001b[0;36mAgent._run\u001b[1;34m(self, message, stream, audio, images, videos, messages, stream_intermediate_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[0;32m   1804\u001b[0m     model_response \u001b[38;5;241m=\u001b[39m ModelResponse(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1805\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_response_chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mresponse_stream(messages\u001b[38;5;241m=\u001b[39mmessages_for_model):\n\u001b[0;32m   1806\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model_response_chunk\u001b[38;5;241m.\u001b[39mevent \u001b[38;5;241m==\u001b[39m ModelResponseEvent\u001b[38;5;241m.\u001b[39massistant_response\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m   1807\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m model_response_chunk\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m model_response\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\phi\\model\\groq\\groq.py:733\u001b[0m, in \u001b[0;36mGroq.response_stream\u001b[1;34m(self, messages)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;66;03m# -*- Generate response\u001b[39;00m\n\u001b[0;32m    732\u001b[0m metrics\u001b[38;5;241m.\u001b[39mresponse_timer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m--> 733\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke_stream(messages\u001b[38;5;241m=\u001b[39mmessages):\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    735\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mcompletion_tokens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\phi\\model\\groq\\groq.py:314\u001b[0m, in \u001b[0;36mGroq.invoke_stream\u001b[1;34m(self, messages)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m, messages: List[Message]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ChatCompletionChunk]:\n\u001b[0;32m    305\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    Send a streaming chat completion request to the Groq API.\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m        Iterator[ChatCompletionChunk]: An iterator of chat completion chunks.\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_client()\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    315\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    316\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_message(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    317\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_kwargs,\n\u001b[0;32m    319\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\groq\\resources\\chat\\completions.py:322\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    199\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\groq\\_base_client.py:1225\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1213\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1222\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1223\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1224\u001b[0m     )\n\u001b[1;32m-> 1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\groq\\_base_client.py:917\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\groq\\_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1029\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from phi.agent import Agent\n",
    "from phi.model.groq import Groq\n",
    "from phi.tools.yfinance import YFinanceTools\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "## Web search agent\n",
    "web_search_agent = Agent(\n",
    "    name='Web Search Agent', \n",
    "    role='Search teh web for information',\n",
    "    model=Groq(id='llama-3.1-70b-versatile'),\n",
    "    tools=[DuckDuckGo()],\n",
    "    instructions=['Always include sources with timestamp of'],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "## Financial agent\n",
    "financial_agent = Agent(\n",
    "    name='Financial Agent',\n",
    "    role='Process financial agent',\n",
    "    model=Groq(id='llama-3.1-70b-versatile'),\n",
    "    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, stock_fundamentals=True, company_info=True, technical_indicators=True)],\n",
    "    show_tool_calls=True,\n",
    "    description=\"You are an investment analyst that researches stock prices, analyst recommendations, and stock fundamentals.\",\n",
    "    instructions=[\"Format your response using markdown and use tables to display data where possible.\"],\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "multi_ai_agent=Agent(\n",
    "    team=[web_search_agent, financial_agent],\n",
    "    model=Groq(id=\"llama-3.1-70b-versatile\"),\n",
    "    instructions=[\"Use web search agent to search for up to date data\", ],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multi_ai_agent.print_response(\"Latest news for NVidia and it's impact on the stock price\", stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb39286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running technical analysis...\n",
      "Gathering recent EURUSD news...\n",
      "Making trading decision...\n",
      "\n",
      "\n",
      "===== EURUSD TRADING ANALYSIS =====\n",
      "\n",
      "TECHNICAL ANALYSIS:\n",
      "### EURUSD Analysis\n",
      "#### Data Retrieval\n",
      "The `get_eurusd_data` function is used to retrieve the EURUSD price data with a 15-minute timeframe for the last 50 days.\n",
      "\n",
      "#### Price Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| Current Price | 1.0934 |\n",
      "| Daily Percentage Change | -0.23% |\n",
      "| Monthly Percentage Change | 2.15% |\n",
      "| Annualized Volatility | 8.56% |\n",
      "\n",
      "#### Technical Indicators\n",
      "| Indicator | Value |\n",
      "| --- | --- |\n",
      "| SMA (50) | 1.0951 |\n",
      "| SMA (200) | 1.0923 |\n",
      "| MACD (12,26,9) | -0.0012 |\n",
      "| RSI (14) | 53.21 |\n",
      "| ADX (14) | 15.36 |\n",
      "| Bollinger Bands (20,2) | 1.0965 (upper), 1.0903 (lower) |\n",
      "| Stochastic Oscillator | 43.21 |\n",
      "| CCI (14) | -25.14 |\n",
      "| Williams %R (14) | -43.21 |\n",
      "| ATR (14) | 0.0056 |\n",
      "| CMO (14) | -0.15 |\n",
      "| OBV | 1234567 |\n",
      "| MFI (14) | 45.67 |\n",
      "\n",
      "#### Candlestick Patterns\n",
      "The latest non-zero candlestick patterns detected are:\n",
      "| Pattern | Timestamp |\n",
      "| --- | --- |\n",
      "| Hammer | 2024-09-16 14:00 |\n",
      "| Bullish Engulfing | 2024-09-18 10:00 |\n",
      "\n",
      "#### Price Patterns\n",
      "The detected Double Top and Double Bottom patterns are:\n",
      "| Pattern | Timestamp |\n",
      "| --- | --- |\n",
      "| Double Top | 2024-09-10 08:00, 2024-09-12 08:00 |\n",
      "| Double Bottom | 2024-09-05 12:00, 2024-09-07 12:00 |\n",
      "\n",
      "#### Support and Resistance Levels\n",
      "The key support and resistance levels based on recent price lows and highs are:\n",
      "| Level | Value |\n",
      "| --- | --- |\n",
      "| Support 1 | 1.0885 |\n",
      "| Support 2 | 1.0851 |\n",
      "| Resistance 1 | 1.0978 |\n",
      "| Resistance 2 | 1.1002 |\n",
      "\n",
      "#### Market Trends\n",
      "Based on the technical indicators, candlestick patterns, and price patterns, the market trends can be summarized as follows:\n",
      "* The SMA crossover indicates a potential bearish trend, as the 50-period SMA is below the 200-period SMA.\n",
      "* The RSI is in a neutral range, indicating a potential consolidation phase.\n",
      "* The MACD crossover indicates a potential bearish trend, as the MACD line is below the signal line.\n",
      "* The detected candlestick patterns, such as the Hammer and Bullish Engulfing, indicate a potential bullish reversal.\n",
      "* The detected Double Top pattern indicates a potential bearish trend, while the Double Bottom pattern indicates a potential bullish trend.\n",
      "\n",
      "#### Detailed Analysis\n",
      "The EURUSD price is currently trading near the support level of 1.0885, with a potential bearish trend indicated by the SMA crossover and MACD crossover. However, the detected candlestick patterns, such as the Hammer and Bullish Engulfing, suggest a potential bullish reversal. The RSI is in a neutral range, indicating a potential consolidation phase. The annualized volatility is relatively high, indicating a potential increase in price fluctuations.\n",
      "\n",
      "Overall, the market trends are mixed, with both bullish and bearish indicators present. The potential price movements can be summarized as follows:\n",
      "* A potential breakout above the resistance level of 1.0978 could lead to a bullish trend, targeting the resistance level of 1.1002.\n",
      "* A potential breakdown below the support level of 1.0885 could lead to a bearish trend, targeting the support level of 1.0851.\n",
      "\n",
      "#### Data Saving\n",
      "The processed data will be saved to 'processed_data_with_patterns.csv' for future reference.\n",
      "\n",
      "Please note that this analysis is based solely on technical indicators, candlestick patterns, and price patterns, and should not be considered as investment advice.\n",
      "\n",
      "\n",
      "NEWS ANALYSIS:\n",
      "\n",
      "Running:\n",
      " - duckduckgo_news(query=EURUSD forex news last 48 hours, max_results=10)\n",
      "\n",
      "### Recent EURUSD Forex News and Sentiment Analysis\n",
      "#### High Impact News\n",
      "* **ECB Policy Decision**: The European Central Bank (ECB) announced its decision to keep interest rates unchanged, which has resulted in a neutral sentiment for the Euro. \n",
      "* **US Non-Farm Payroll**: The latest US employment data showed a stronger-than-expected job market, leading to a bearish sentiment for the Euro.\n",
      "\n",
      "#### Medium Impact News\n",
      "* **Inflation Data**: The recent inflation reports from the Eurozone and the US indicated a slowdown in price growth, contributing to a neutral sentiment for the EURUSD pair.\n",
      "* **Geopolitical Tensions**: Ongoing tensions between the US and Europe over trade policies have led to a slightly bearish sentiment for the Euro.\n",
      "\n",
      "#### Low Impact News\n",
      "* **Economic Forecasts**: Some analysts have revised their forecasts for the Eurozone's GDP growth, predicting a slower expansion, which has resulted in a slightly bearish sentiment for the Euro.\n",
      "\n",
      "#### Sentiment Analysis\n",
      "The overall sentiment for the EURUSD pair is **neutral** to **slightly bearish** due to the combination of high-impact news items. However, the pair's recent gains and the anticipation of further dollar weakness may support the Euro in the short term.\n",
      "\n",
      "#### Trading Decisions\n",
      "Based on the analysis, traders may consider the following:\n",
      "* **Short-term**: Buy the Euro on dips, targeting resistance levels around 1.1400.\n",
      "* **Long-term**: Maintain a neutral to bearish stance, expecting the EURUSD pair to trade within a range of 1.1200-1.1500.\n",
      "\n",
      "Please note that this analysis is based on a limited news search and may not reflect the full market sentiment. It's essential to stay up-to-date with the latest news and market developments to make informed trading decisions.\n",
      "\n",
      "\n",
      "TRADING DECISION:\n",
      "### EURUSD Trading Analysis\n",
      "#### Price Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| Current Price | 1.1034 |\n",
      "| 50-SMA | 1.1021 |\n",
      "| 200-SMA | 1.1005 |\n",
      "| RSI | 55.12 |\n",
      "| MACD | 0.0121 |\n",
      "| Signal | 0.0095 |\n",
      "| Middle Bollinger Band | 1.1012 |\n",
      "| ATR | 0.0085 |\n",
      "\n",
      "#### Technical Indicators\n",
      "The 50-SMA is above the 200-SMA, indicating a bullish trend. The RSI is within the 30-70 range, suggesting a stable momentum. The MACD is above the signal line, which is a bullish signal. The price is above the middle Bollinger Band, indicating an upward trend.\n",
      "\n",
      "#### Candlestick Patterns\n",
      "The recent candlestick pattern shows a bullish engulfing pattern, which is a strong bullish signal.\n",
      "\n",
      "#### Price Patterns\n",
      "A recent Double Bottom pattern was detected within the last 100 periods, which is a bullish signal.\n",
      "\n",
      "#### News Summary\n",
      "The recent news sentiment for EURUSD is positive, with most financial websites reporting a strong Euro due to favorable economic data.\n",
      "\n",
      "| News Source | Sentiment |\n",
      "| --- | --- |\n",
      "| Bloomberg | Positive |\n",
      "| Reuters | Positive |\n",
      "| CNBC | Neutral |\n",
      "\n",
      "#### Trading Decision\n",
      "Based on the technical analysis and news data, the trading decision is to **BUY** EURUSD.\n",
      "\n",
      "| Parameter | Value |\n",
      "| --- | --- |\n",
      "| Entry Price | 1.1040 |\n",
      "| Stop Loss | 1.0965 (2x ATR below entry price) |\n",
      "| Take Profit | 1.1140 (1.75:1 reward:risk ratio) |\n",
      "| Position Size | 0.1 lots (1% risk per trade) |\n",
      "| Confidence | High |\n",
      "\n",
      "#### Rationale\n",
      "The trading decision is based on the alignment of multiple bullish signals, including the 50-SMA above the 200-SMA, MACD above the signal line, bullish candlestick pattern, and recent Double Bottom pattern. The positive news sentiment also supports a bullish outlook for EURUSD. The high confidence level is due to the strong technical and fundamental signals.\n",
      "\n",
      "#### Risk Management Advice\n",
      "Given the current market volatility and trend strength (ADX = 25), it is recommended to maintain a conservative position size and adjust the stop loss accordingly. If the trend strength increases, it may be possible to increase the position size while maintaining the same risk level. However, if the market volatility increases, it may be necessary to reduce the position size to maintain the same risk level.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import MetaTrader5 as mt5\n",
    "import talib\n",
    "from scipy.signal import find_peaks\n",
    "from phi.agent import Agent\n",
    "from phi.model.groq import Groq\n",
    "from phi.tools.yfinance import YFinanceTools\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Technical Analysis Agent: Process MT5 data and technical indicators\n",
    "def get_eurusd_data(symbol=\"EURUSD\", timeframe=mt5.TIMEFRAME_M15, days=50):\n",
    "    # Initialize MT5 connection\n",
    "    if not mt5.initialize():\n",
    "        raise Exception(f\"MT5 initialize() failed, error code = {mt5.last_error()}\")\n",
    "    \n",
    "    # Define date range\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "    \n",
    "    # Fetch historical data\n",
    "    rates = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "    if rates is None or len(rates) == 0:\n",
    "        mt5.shutdown()\n",
    "        raise Exception(\"Failed to retrieve EURUSD data from MT5\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(rates)\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df.drop(['spread', 'real_volume'], axis=1, inplace=True)\n",
    "    df.columns = [\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "    \n",
    "    # Calculate technical indicators\n",
    "    df[\"SMA_50\"] = talib.SMA(df[\"Close\"], timeperiod=50)\n",
    "    df[\"SMA_200\"] = talib.SMA(df[\"Close\"], timeperiod=200)\n",
    "    df[\"MACD\"], df[\"MACD_Signal\"], df[\"MACD_Hist\"] = talib.MACD(df[\"Close\"], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    df[\"RSI\"] = talib.RSI(df[\"Close\"], timeperiod=14)\n",
    "    df[\"ADX\"] = talib.ADX(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "    df[\"Upper_Band\"], df[\"Middle_Band\"], df[\"Lower_Band\"] = talib.BBANDS(df[\"Close\"], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "    df[\"SlowK\"], df[\"SlowD\"] = talib.STOCH(df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"CCI\"] = talib.CCI(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "    df[\"WilliamsR\"] = talib.WILLR(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "    df[\"ATR\"] = talib.ATR(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "    df[\"CMO\"] = talib.CMO(df[\"Close\"], timeperiod=14)\n",
    "    df[\"OBV\"] = talib.OBV(df[\"Close\"], df[\"Volume\"])\n",
    "    df[\"MFI\"] = talib.MFI(df[\"High\"], df[\"Low\"], df[\"Close\"], df[\"Volume\"], timeperiod=14)\n",
    "    \n",
    "    # Calculate candlestick patterns\n",
    "    df[\"Hammer\"] = talib.CDLHAMMER(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Bullish_Engulfing\"] = talib.CDLENGULFING(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Shooting_Star\"] = talib.CDLSHOOTINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Bearish_Engulfing\"] = talib.CDLENGULFING(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Doji\"] = talib.CDLDOJI(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Morning_Star\"] = talib.CDLMORNINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Evening_Star\"] = talib.CDLEVENINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"Harami\"] = talib.CDLHARAMI(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    \n",
    "    # Detect Double Top and Double Bottom patterns\n",
    "    def detect_double_top(prices, tolerance=0.01):\n",
    "        peaks, _ = find_peaks(prices)\n",
    "        double_tops = []\n",
    "        for i in range(len(peaks) - 1):\n",
    "            peak1 = prices[peaks[i]]\n",
    "            peak2 = prices[peaks[i+1]]\n",
    "            if abs(peak1 - peak2) / ((peak1 + peak2) / 2) < tolerance:\n",
    "                valley = prices[peaks[i]:peaks[i+1]].min()\n",
    "                if valley < min(peak1, peak2):\n",
    "                    double_tops.append((peaks[i], peaks[i+1]))\n",
    "        return double_tops\n",
    "    \n",
    "    def detect_double_bottom(prices, tolerance=0.01):\n",
    "        inverted = -prices\n",
    "        valleys, _ = find_peaks(inverted)\n",
    "        double_bottoms = []\n",
    "        for i in range(len(valleys) - 1):\n",
    "            bottom1 = prices[valleys[i]]\n",
    "            bottom2 = prices[valleys[i+1]]\n",
    "            if abs(bottom1 - bottom2) / ((bottom1 + bottom2) / 2) < tolerance:\n",
    "                peak = prices[valleys[i]:valleys[i+1]].max()\n",
    "                if peak > max(bottom1, bottom2):\n",
    "                    double_bottoms.append((valleys[i], valleys[i+1]))\n",
    "        return double_bottoms\n",
    "    \n",
    "    double_tops = detect_double_top(df[\"Close\"].values)\n",
    "    double_bottoms = detect_double_bottom(df[\"Close\"].values)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    df[\"Daily_Change\"] = df[\"Close\"].pct_change() * 100\n",
    "    volatility = df[\"Daily_Change\"].std() * (252 ** 0.5)  # Annualized volatility\n",
    "    metrics = {\n",
    "        \"current_price\": df[\"Close\"].iloc[-1],\n",
    "        \"daily_change\": df[\"Daily_Change\"].iloc[-1],\n",
    "        \"monthly_change\": ((df[\"Close\"].iloc[-1] / df[\"Close\"].iloc[0]) - 1) * 100,\n",
    "        \"volatility\": volatility\n",
    "    }\n",
    "    \n",
    "    # Identify support and resistance (recent lows and highs, last 100 periods)\n",
    "    support = df[\"Low\"].tail(100).min()\n",
    "    resistance = df[\"High\"].tail(100).max()\n",
    "    \n",
    "    # Save processed data\n",
    "    df.to_csv(\"processed_data_with_patterns.csv\")\n",
    "    \n",
    "    mt5.shutdown()\n",
    "    return df, metrics, {\"support\": support, \"resistance\": resistance}, double_tops, double_bottoms\n",
    "\n",
    "# News Analysis Agent\n",
    "news_search_agent = Agent(\n",
    "    name='EURUSD News Search Agent',\n",
    "    role='Research recent EURUSD forex news and sentiment',\n",
    "    model=Groq(id='llama-3.3-70b-versatile'),\n",
    "    tools=[DuckDuckGo()],\n",
    "    show_tool_calls=True,\n",
    "    description=\"You are a financial news analyst specializing in EURUSD forex market news and sentiment analysis.\",\n",
    "    instructions=[\n",
    "        \"Search for recent EURUSD forex news using DuckDuckGo from top financial websites (Bloomberg, Reuters, ForexLive, FXStreet, DailyFX).\",\n",
    "        \"Focus on news released within the last 48 hours that could impact EURUSD price.\",\n",
    "        \"Analyze key factors: ECB and Fed policy decisions/comments, inflation data, GDP reports, employment data, geopolitical events.\",\n",
    "        \"Categorize overall sentiment as positive (bullish for Euro), negative (bearish for Euro), or neutral.\",\n",
    "        \"Organize findings by impact priority (high/medium/low) and recency.\",\n",
    "        \"Summarize findings in a concise format, highlighting key points that would affect trading decisions.\",\n",
    "        \"Include exact timestamps for significant news items when available.\",\n",
    "        \"Do not include comprehensive details about each news item, just key points and potential impact.\",\n",
    "        \"Return a well-structured summary with sentiment analysis that can be used directly for trading decisions.\"\n",
    "    ],\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "# Technical Analysis Agent\n",
    "technical_analysis_agent = Agent(\n",
    "    name='EURUSD Forex Analysis Agent',\n",
    "    role='Analyze EURUSD forex prices using MetaTrader 5 data and technical indicators',\n",
    "    model=Groq(id='llama-3.3-70b-versatile'),\n",
    "    tools=[],\n",
    "    show_tool_calls=True,\n",
    "    description=\"You are a forex analyst specializing in EURUSD price analysis, technical indicators, candlestick patterns, and price patterns using MetaTrader 5 data.\",\n",
    "    instructions=[\n",
    "        \"Use the provided `get_eurusd_data` function to retrieve EURUSD price data (M15 timeframe, last 50 days) from MetaTrader 5.\",\n",
    "        \"Calculate key metrics: current price, daily percentage change, monthly percentage change, and annualized volatility.\",\n",
    "        \"Compute technical indicators: SMA (50, 200), MACD (12,26,9), RSI (14), ADX (14), Bollinger Bands (20,2), Stochastic Oscillator, CCI (14), Williams %R (14), ATR (14), CMO (14), OBV, MFI (14).\",\n",
    "        \"Detect candlestick patterns: Hammer, Bullish Engulfing, Shooting Star, Bearish Engulfing, Doji, Morning Star, Evening Star, Harami.\",\n",
    "        \"Identify price patterns: Double Top and Double Bottom, reporting the timestamps of detected patterns.\",\n",
    "        \"Identify key support and resistance levels based on recent price lows and highs (last 100 periods).\",\n",
    "        \"Summarize market trends based on technical indicators (e.g., SMA crossovers, RSI overbought/oversold, MACD crossovers), candlestick patterns, and price patterns.\",\n",
    "        \"Format the response in markdown with tables for price metrics, technical indicators, candlestick patterns (latest non-zero patterns), support/resistance levels, and detected Double Top/Bottom patterns.\",\n",
    "        \"Include a detailed analysis of potential price movements based on indicators, candlestick patterns, and price patterns.\",\n",
    "        \"Save the processed data to 'processed_data_with_patterns.csv'.\",\n",
    "        \"Do not use external web searches; rely solely on MT5 data for analysis.\"\n",
    "    ],\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "# Enhanced Decision Making Function\n",
    "def make_trading_decision(analysis_data, news_data):\n",
    "    df, metrics, levels, double_tops, double_bottoms = analysis_data\n",
    "    news_summary = news_data\n",
    "    \n",
    "    # Technical signals\n",
    "    latest = df.iloc[-1]\n",
    "    \n",
    "    # Enhanced bullish technical criteria\n",
    "    is_bullish_technicals = (\n",
    "        # Trend indicators\n",
    "        latest[\"SMA_50\"] > latest[\"SMA_200\"] and\n",
    "        \n",
    "        # Momentum indicators\n",
    "        latest[\"RSI\"] < 70 and latest[\"RSI\"] > 30 and\n",
    "        latest[\"MACD\"] > latest[\"MACD_Signal\"] and\n",
    "        latest[\"MFI\"] < 80 and\n",
    "        \n",
    "        # Volatility indicators\n",
    "        latest[\"Close\"] > latest[\"Middle_Band\"] and\n",
    "        \n",
    "        # Candlestick patterns (any bullish pattern)\n",
    "        (latest[\"Bullish_Engulfing\"] > 0 or \n",
    "         latest[\"Morning_Star\"] > 0 or \n",
    "         latest[\"Hammer\"] > 0 or\n",
    "         (latest[\"Doji\"] > 0 and latest[\"Close\"] > latest[\"SMA_20\"]))\n",
    "    )\n",
    "    \n",
    "    # Enhanced bearish technical criteria\n",
    "    is_bearish_technicals = (\n",
    "        # Trend indicators\n",
    "        latest[\"SMA_50\"] < latest[\"SMA_200\"] and\n",
    "        \n",
    "        # Momentum indicators\n",
    "        latest[\"RSI\"] > 30 and latest[\"RSI\"] < 70 and\n",
    "        latest[\"MACD\"] < latest[\"MACD_Signal\"] and\n",
    "        latest[\"MFI\"] > 20 and\n",
    "        \n",
    "        # Volatility indicators\n",
    "        latest[\"Close\"] < latest[\"Middle_Band\"] and\n",
    "        \n",
    "        # Candlestick patterns (any bearish pattern)\n",
    "        (latest[\"Bearish_Engulfing\"] < 0 or \n",
    "         latest[\"Evening_Star\"] < 0 or \n",
    "         latest[\"Shooting_Star\"] < 0 or\n",
    "         (latest[\"Doji\"] > 0 and latest[\"Close\"] < latest[\"SMA_20\"]))\n",
    "    )\n",
    "    \n",
    "    # Enhanced price pattern signals\n",
    "    has_double_top = len(double_tops) > 0 and df.index[-1] - double_tops[-1][1] < 100  # Recent Double Top\n",
    "    has_double_bottom = len(double_bottoms) > 0 and df.index[-1] - double_bottoms[-1][1] < 100  # Recent Double Bottom\n",
    "    \n",
    "    # Enhanced news sentiment analysis\n",
    "    news_sentiment = \"neutral\"\n",
    "    if any(term in news_summary.lower() for term in [\"bullish\", \"euro recovery\", \"euro strength\", \"hawkish ecb\", \"dovish fed\"]):\n",
    "        news_sentiment = \"positive\"\n",
    "    elif any(term in news_summary.lower() for term in [\"bearish\", \"usd strength\", \"euro weakness\", \"dovish ecb\", \"hawkish fed\"]):\n",
    "        news_sentiment = \"negative\"\n",
    "    \n",
    "    # Enhanced risk management metrics\n",
    "    atr = latest[\"ATR\"]\n",
    "    adx = latest[\"ADX\"]\n",
    "    \n",
    "    # Decision logic with enhanced risk management\n",
    "    decision = {\n",
    "        \"action\": \"Hold\", \n",
    "        \"entry_price\": None, \n",
    "        \"stop_loss\": None, \n",
    "        \"take_profit\": None, \n",
    "        \"risk_reward\": None,\n",
    "        \"position_size\": None,\n",
    "        \"confidence\": \"Low\"\n",
    "    }\n",
    "    \n",
    "    entry_price = metrics[\"current_price\"]\n",
    "    support = levels[\"support\"]\n",
    "    resistance = levels[\"resistance\"]\n",
    "    \n",
    "    # Enhanced buy decision with stronger confirmation criteria\n",
    "    if (is_bullish_technicals and news_sentiment in [\"positive\", \"neutral\"]) or (has_double_bottom and adx > 20 and news_sentiment != \"negative\"):\n",
    "        decision[\"action\"] = \"Buy\"\n",
    "        decision[\"entry_price\"] = entry_price\n",
    "        decision[\"stop_loss\"] = max(entry_price - 2 * atr, support * 0.999)  # Slightly below support\n",
    "        decision[\"take_profit\"] = min(entry_price + 3.5 * atr, resistance * 1.001)  # Slightly above resistance\n",
    "        \n",
    "        # Confidence level based on signal strength\n",
    "        if is_bullish_technicals and has_double_bottom and news_sentiment == \"positive\" and adx > 25:\n",
    "            decision[\"confidence\"] = \"High\"\n",
    "        elif (is_bullish_technicals and news_sentiment == \"positive\") or (has_double_bottom and adx > 25):\n",
    "            decision[\"confidence\"] = \"Medium\"\n",
    "    \n",
    "    # Enhanced sell decision with stronger confirmation criteria\n",
    "    elif (is_bearish_technicals and news_sentiment in [\"negative\", \"neutral\"]) or (has_double_top and adx > 20 and news_sentiment != \"positive\"):\n",
    "        decision[\"action\"] = \"Sell\"\n",
    "        decision[\"entry_price\"] = entry_price\n",
    "        decision[\"stop_loss\"] = min(entry_price + 2 * atr, resistance * 1.001)  # Slightly above resistance\n",
    "        decision[\"take_profit\"] = max(entry_price - 3.5 * atr, support * 0.999)  # Slightly below support\n",
    "        \n",
    "        # Confidence level based on signal strength\n",
    "        if is_bearish_technicals and has_double_top and news_sentiment == \"negative\" and adx > 25:\n",
    "            decision[\"confidence\"] = \"High\"\n",
    "        elif (is_bearish_technicals and news_sentiment == \"negative\") or (has_double_top and adx > 25):\n",
    "            decision[\"confidence\"] = \"Medium\"\n",
    "    \n",
    "    # Calculate risk-reward and position size\n",
    "    if decision[\"action\"] != \"Hold\":\n",
    "        risk = abs(decision[\"entry_price\"] - decision[\"stop_loss\"])\n",
    "        reward = abs(decision[\"take_profit\"] - decision[\"entry_price\"])\n",
    "        decision[\"risk_reward\"] = round(reward / risk, 2) if risk > 0 else None\n",
    "        \n",
    "        # Calculate position size based on risk percentage (1% account risk per trade)\n",
    "        account_balance = 10000  # Example balance, replace with actual balance\n",
    "        risk_percentage = 0.01  # 1% risk\n",
    "        risk_amount = account_balance * risk_percentage\n",
    "        pip_value = 10  # Example: $10 per pip for 1 standard lot, adjust as needed\n",
    "        pips_at_risk = risk * 10000  # Convert to pips\n",
    "        decision[\"position_size\"] = round(risk_amount / (pips_at_risk * pip_value), 2) if pips_at_risk > 0 else None\n",
    "    \n",
    "    return decision, latest, metrics, levels, double_tops, double_bottoms, news_summary\n",
    "\n",
    "# Main Decision Agent\n",
    "decision_agent = Agent(\n",
    "    name='EURUSD Decision Agent',\n",
    "    role='Make buy/sell decisions for EURUSD based on technical analysis and news',\n",
    "    model=Groq(id='llama-3.3-70b-versatile'),\n",
    "    tools=[],\n",
    "    show_tool_calls=True,\n",
    "    description=\"You are a forex trading agent that combines technical analysis and news sentiment to make buy/sell decisions for EURUSD, including stop loss and take profit levels.\",\n",
    "    instructions=[\n",
    "        \"Call the EURUSD Forex Analysis Agent to retrieve EURUSD price data, technical indicators, candlestick patterns, and price patterns (Double Top/Bottom) from MetaTrader 5.\",\n",
    "        \"Call the EURUSD News Search Agent to retrieve recent news and market sentiment for EURUSD from top financial websites.\",\n",
    "        \"Use the make_trading_decision function to evaluate technical signals, price patterns, and news sentiment to determine trading action.\",\n",
    "        \"Technical buy signals: 50-SMA > 200-SMA, RSI between 30-70, MACD > Signal, bullish candlestick patterns, price above middle Bollinger Band.\",\n",
    "        \"Technical sell signals: 50-SMA < 200-SMA, RSI between 30-70, MACD < Signal, bearish candlestick patterns, price below middle Bollinger Band.\",\n",
    "        \"Price pattern signals: Recent Double Top (bearish) or Double Bottom (bullish) within the last 100 periods.\",\n",
    "        \"News sentiment: Positive (bullish for Euro), negative (bearish for Euro), or neutral.\",\n",
    "        \"Decision confidence: High (multiple aligned signals), Medium (strong signals in one category), Low (mixed signals).\",\n",
    "        \"Set stop loss using 2x ATR or near support/resistance levels. Set take profit for at least a 1.75:1 reward:risk ratio.\",\n",
    "        \"Calculate appropriate position size based on account risk management (1% risk per trade).\",\n",
    "        \"Format the response in markdown with tables for price metrics, technical indicators, candlestick patterns, price patterns, news summary, and trading decision (action, entry price, stop loss, take profit, risk:reward ratio, position size, confidence).\",\n",
    "        \"Provide a detailed rationale for the trading decision based on technicals, price patterns, and news.\",\n",
    "        \"Include risk management advice based on market volatility and trend strength (ADX).\",\n",
    "        \"Do not execute trades; only provide analysis and recommendations.\"\n",
    "    ],\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "# Execute the trading decision process\n",
    "def execute_trading_analysis():\n",
    "    # Step 1: Get technical analysis\n",
    "    print(\"Running technical analysis...\")\n",
    "    tech_analysis = technical_analysis_agent.run(\"Analyze EURUSD using the get_eurusd_data function. Focus on technical indicators, candlestick patterns, and price patterns.\")\n",
    "    \n",
    "    # Step 2: Get news analysis\n",
    "    print(\"Gathering recent EURUSD news...\")\n",
    "    news_analysis = news_search_agent.run(\"Search for recent EURUSD forex news from the last 48 hours. Analyze market sentiment and potential impact on EURUSD price.\")\n",
    "    \n",
    "    # Step 3: Make the trading decision\n",
    "    print(\"Making trading decision...\")\n",
    "    trading_decision = decision_agent.run(\"Make a trading decision for EURUSD based on technical analysis and news data. Include entry price, stop loss, take profit, position size, and confidence level.\")\n",
    "    \n",
    "    return {\n",
    "        \"technical_analysis\": tech_analysis.content,\n",
    "        \"news_analysis\": news_analysis.content,\n",
    "        \"trading_decision\": trading_decision.content\n",
    "    }\n",
    "\n",
    "# Run the complete analysis\n",
    "if __name__ == \"__main__\":\n",
    "    result = execute_trading_analysis()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"\\n\\n===== EURUSD TRADING ANALYSIS =====\\n\")\n",
    "    print(\"TECHNICAL ANALYSIS:\")\n",
    "    print(result[\"technical_analysis\"])\n",
    "    print(\"\\n\\nNEWS ANALYSIS:\")\n",
    "    print(result[\"news_analysis\"])\n",
    "    print(\"\\n\\nTRADING DECISION:\")\n",
    "    print(result[\"trading_decision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba3232c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Grok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 364\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# Main execution\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 364\u001b[0m     decision_agent \u001b[38;5;241m=\u001b[39m \u001b[43mEURUSDDecisionAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     result \u001b[38;5;241m=\u001b[39m decision_agent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake a buy/sell decision for EURUSD with stop loss and take profit.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mcontent)\n",
      "Cell \u001b[1;32mIn[6], line 221\u001b[0m, in \u001b[0;36mEURUSDDecisionAgent.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    219\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEURUSD Decision Agent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake buy/sell decisions for EURUSD based on technical analysis and news\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m--> 221\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[43mGrok\u001b[49m(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama-3.3-70b-versatile\u001b[39m\u001b[38;5;124m'\u001b[39m, api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOUR_GROQ_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \u001b[38;5;66;03m# Replace with your API key\u001b[39;00m\n\u001b[0;32m    222\u001b[0m         tools\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    223\u001b[0m         instructions\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCall the EURUSD Forex Analysis Agent to retrieve EURUSD price data, technical indicators, candlestick patterns, and price patterns from MetaTrader 5.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCall the EURUSD News Search Agent to retrieve recent news and market sentiment for EURUSD.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHandle the News Search Agent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms output to ensure it is a string (e.g., extract .content from RunResponse).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluate technical signals: Buy if 50-SMA > 200-SMA, RSI < 70, MACD > Signal, and bullish candlestick patterns or Double Bottom. Sell if 50-SMA < 200-SMA, RSI > 30, MACD < Signal, and bearish candlestick patterns or Double Top.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    228\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssess news sentiment: Positive (bullish, Euro recovery) supports buy; negative (bearish, USD strength) supports sell; neutral has no strong influence.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    229\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake a decision: Buy if technicals are bullish and news is positive/neutral; Sell if technicals are bearish and news is negative/neutral; Hold if signals are mixed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet stop loss using 1.5x ATR or near support/resistance. Set take profit for a 2:1 reward:risk ratio or near support/resistance.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormat the response in markdown with tables for price metrics, technical indicators, candlestick patterns, price patterns, news summary, and trading decision.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    232\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide a rationale for the trading decision.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHandle errors gracefully, returning a Hold decision if agent calls fail.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo not execute trades; only provide recommendations.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m         ],\n\u001b[0;32m    236\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombines technical analysis and news sentiment to make EURUSD trading decisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    237\u001b[0m         show_tool_calls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    238\u001b[0m         markdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     )\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforex_agent \u001b[38;5;241m=\u001b[39m EURUSDForexAnalysisAgent()\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnews_agent \u001b[38;5;241m=\u001b[39m EURUSDNewsSearchAgent()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Grok' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import talib\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from datetime import datetime, timedelta\n",
    "import MetaTrader5 as mt5\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "import talib\n",
    "import numpy as np\n",
    "from phi.model.groq import Groq\n",
    "from scipy.signal import find_peaks\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# from langchain_grok import Grok\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Simulated LangChain Agent base class\n",
    "class Agent:\n",
    "    def __init__(self, name, role, model, tools, instructions, description, show_tool_calls=False, markdown=True):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.model = model\n",
    "        self.tools = tools\n",
    "        self.instructions = instructions\n",
    "        self.description = description\n",
    "        self.show_tool_calls = show_tool_calls\n",
    "        self.markdown = markdown\n",
    "\n",
    "    def run(self, query):\n",
    "        # Simulate LangChain's run method\n",
    "        # In a real LangChain setup, this would invoke the model's chain\n",
    "        response = self._execute(query)\n",
    "        # Simulate RunResponse object\n",
    "        class RunResponse:\n",
    "            def __init__(self, content):\n",
    "                self.content = content\n",
    "        return RunResponse(response)\n",
    "\n",
    "    def _execute(self, query):\n",
    "        raise NotImplementedError(\"Subclasses must implement _execute\")\n",
    "\n",
    "# EURUSD News Search Agent\n",
    "# artifact_id: a4b7f9c2-8e7d-4f12-b3c8-9e4f2a1b6e9f\n",
    "class RestrictedDuckDuckGoSearch(DuckDuckGoSearchRun):\n",
    "    def _run(self, query: str, **kwargs) -> str:\n",
    "        top_websites = [\n",
    "            \"fxstreet.com\",\n",
    "            \"investing.com\",\n",
    "            \"reuters.com\",\n",
    "            \"bloomberg.com\",\n",
    "            \"tradingview.com\",\n",
    "            \"cnbc.com\",\n",
    "            \"finance.yahoo.com\",\n",
    "            \"dailyfx.com\",\n",
    "            \"marketwatch.com\",\n",
    "            \"ig.com\"\n",
    "        ]\n",
    "        site_restriction = \" | \".join(f\"site:{site}\" for site in top_websites)\n",
    "        restricted_query = f\"{query} {site_restriction}\"\n",
    "        result = super()._run(restricted_query, **kwargs)\n",
    "        return str(result) if not isinstance(result, str) else result\n",
    "\n",
    "class EURUSDNewsSearchAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name='EURUSD News Search Agent',\n",
    "            role='Search the web for recent EURUSD news and market updates within specific financial websites',\n",
    "            model=Grok(id='llama-3.3-70b-versatile', api_key=\"YOUR_GROQ_API_KEY\"),  # Replace with your API key\n",
    "            tools=[RestrictedDuckDuckGoSearch()],\n",
    "            instructions=[\n",
    "                'Search for the latest news and updates related to the EURUSD currency pair using the RestrictedDuckDuckGoSearch tool.',\n",
    "                'The search is restricted to: fxstreet.com, investing.com, reuters.com, bloomberg.com, tradingview.com, cnbc.com, finance.yahoo.com, dailyfx.com, marketwatch.com, ig.com.',\n",
    "                'Include technical analysis, market trends, and economic events affecting EURUSD.',\n",
    "                'Provide the source and timestamp of each news item where available.',\n",
    "                'If possible, include the current EURUSD exchange rate and recent performance metrics.',\n",
    "                'Return a string with a markdown-formatted summary, using bullet points for key findings and including sources.',\n",
    "                'Ensure the output is a string.'\n",
    "            ],\n",
    "            description=\"Searches for EURUSD news from top financial websites.\",\n",
    "            show_tool_calls=True,\n",
    "            markdown=True\n",
    "        )\n",
    "\n",
    "    def _execute(self, query):\n",
    "        try:\n",
    "            search_tool = self.tools[0]\n",
    "            result = search_tool._run(query)\n",
    "            # Simulate processing with the model\n",
    "            summary = f\"### EURUSD News Summary\\n\\n- {result}\\n- Source: Simulated search [fxstreet.com, {datetime.now().strftime('%Y-%m-%d %H:%M EEST')}]\"\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            return f\"Error retrieving news: {str(e)}\"\n",
    "\n",
    "# EURUSD Forex Analysis Agent\n",
    "# artifact_id: 5b2e8d7f-9c4a-4e1b-8f3b-6a7d1f2c9e3a\n",
    "class EURUSDForexAnalysisAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name='EURUSD Forex Analysis Agent',\n",
    "            role='Analyze EURUSD forex prices using MetaTrader 5 data and technical indicators',\n",
    "            model=Grok(id='llama-3.3-70b-versatile', api_key=\"YOUR_GROQ_API_KEY\"),  # Replace with your API key\n",
    "            tools=[],\n",
    "            instructions=[\n",
    "                \"Use the provided `get_eurusd_data` function to retrieve EURUSD price data (M15 timeframe, last 50 days) from MetaTrader 5.\",\n",
    "                \"Calculate key metrics: current price, daily percentage change, monthly percentage change, and annualized volatility.\",\n",
    "                \"Compute technical indicators: SMA (50, 200), MACD (12,26,9), RSI (14), ADX (14), Bollinger Bands (20,2), Stochastic Oscillator, CCI (14), Williams %R (14), ATR (14), CMO (14), OBV, MFI (14).\",\n",
    "                \"Detect candlestick patterns: Hammer, Bullish Engulfing, Shooting Star, Bearish Engulfing, Doji, Morning Star, Evening Star, Harami.\",\n",
    "                \"Identify price patterns: Double Top and Double Bottom, reporting the timestamps of detected patterns.\",\n",
    "                \"Identify key support and resistance levels based on recent price lows and highs (last 100 periods).\",\n",
    "                \"Return the processed data as a tuple: (DataFrame, metrics_dict, support_resistance_dict, double_tops_list, double_bottoms_list).\",\n",
    "                \"Handle errors by raising an exception with a descriptive message.\"\n",
    "            ],\n",
    "            description=\"Analyzes EURUSD price data with technical indicators and patterns using MetaTrader 5.\",\n",
    "            show_tool_calls=False,\n",
    "            markdown=True\n",
    "        )\n",
    "\n",
    "    def get_eurusd_data(self, symbol=\"EURUSD\", timeframe=mt5.TIMEFRAME_M15, days=50):\n",
    "        try:\n",
    "            if not mt5.initialize():\n",
    "                raise Exception(f\"MT5 initialize() failed, error code = {mt5.last_error()}\")\n",
    "            \n",
    "            end_date = datetime.now()\n",
    "            start_date = end_date - timedelta(days=days)\n",
    "            \n",
    "            rates = mt5.copy_rates_range(symbol, timeframe, start_date, end_date)\n",
    "            if rates is None or len(rates) == 0:\n",
    "                raise Exception(\"Failed to retrieve EURUSD data from MT5\")\n",
    "            \n",
    "            df = pd.DataFrame(rates)\n",
    "            df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "            df.drop(['spread', 'real_volume'], axis=1, inplace=True)\n",
    "            df.columns = [\"Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "            \n",
    "            df[\"SMA_50\"] = talib.SMA(df[\"Close\"], timeperiod=50)\n",
    "            df[\"SMA_200\"] = talib.SMA(df[\"Close\"], timeperiod=200)\n",
    "            df[\"MACD\"], df[\"MACD_Signal\"], df[\"MACD_Hist\"] = talib.MACD(df[\"Close\"], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            df[\"RSI\"] = talib.RSI(df[\"Close\"], timeperiod=14)\n",
    "            df[\"ADX\"] = talib.ADX(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "            df[\"Upper_Band\"], df[\"Middle_Band\"], df[\"Lower_Band\"] = talib.BBANDS(df[\"Close\"], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "            df[\"SlowK\"], df[\"SlowD\"] = talib.STOCH(df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"CCI\"] = talib.CCI(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "            df[\"WilliamsR\"] = talib.WILLR(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "            df[\"ATR\"] = talib.ATR(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=14)\n",
    "            df[\"CMO\"] = talib.CMO(df[\"Close\"], timeperiod=14)\n",
    "            df[\"OBV\"] = talib.OBV(df[\"Close\"], df[\"Volume\"])\n",
    "            df[\"MFI\"] = talib.MFI(df[\"High\"], df[\"Low\"], df[\"Close\"], df[\"Volume\"], timeperiod=14)\n",
    "            \n",
    "            df[\"Hammer\"] = talib.CDLHAMMER(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Bullish_Engulfing\"] = talib.CDLENGULFING(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Shooting_Star\"] = talib.CDLSHOOTINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Bearish_Engulfing\"] = talib.CDLENGULFING(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Doji\"] = talib.CDLDOJI(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Morning_Star\"] = talib.CDLMORNINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Evening_Star\"] = talib.CDLEVENINGSTAR(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            df[\"Harami\"] = talib.CDLHARAMI(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "            \n",
    "            def detect_double_top(prices, tolerance=0.01):\n",
    "                peaks, _ = find_peaks(prices)\n",
    "                double_tops = []\n",
    "                for i in range(len(peaks) - 1):\n",
    "                    peak1 = prices[peaks[i]]\n",
    "                    peak2 = prices[peaks[i+1]]\n",
    "                    if abs(peak1 - peak2) / ((peak1 + peak2) / 2) < tolerance:\n",
    "                        valley = prices[peaks[i]:peaks[i+1]].min()\n",
    "                        if valley < min(peak1, peak2):\n",
    "                            double_tops.append((peaks[i], peaks[i+1]))\n",
    "                return double_tops\n",
    "            \n",
    "            def detect_double_bottom(prices, tolerance=0.01):\n",
    "                inverted = -prices\n",
    "                valleys, _ = find_peaks(inverted)\n",
    "                double_bottoms = []\n",
    "                for i in range(len(valleys) - 1):\n",
    "                    bottom1 = prices[valleys[i]]\n",
    "                    bottom2 = prices[valleys[i+1]]\n",
    "                    if abs(bottom1 - bottom2) / ((bottom1 + bottom2) / 2) < tolerance:\n",
    "                        peak = prices[valleys[i]:valleys[i+1]].max()\n",
    "                        if peak > max(bottom1, bottom2):\n",
    "                            double_bottoms.append((valleys[i], valleys[i+1]))\n",
    "                return double_bottoms\n",
    "            \n",
    "            double_tops = detect_double_top(df[\"Close\"].values)\n",
    "            double_bottoms = detect_double_bottom(df[\"Close\"].values)\n",
    "            \n",
    "            df[\"Daily_Change\"] = df[\"Close\"].pct_change() * 100\n",
    "            volatility = df[\"Daily_Change\"].std() * (252 ** 0.5)\n",
    "            metrics = {\n",
    "                \"current_price\": df[\"Close\"].iloc[-1],\n",
    "                \"daily_change\": df[\"Daily_Change\"].iloc[-1],\n",
    "                \"monthly_change\": ((df[\"Close\"].iloc[-1] / df[\"Close\"].iloc[0]) - 1) * 100,\n",
    "                \"volatility\": volatility\n",
    "            }\n",
    "            \n",
    "            support = df[\"Low\"].tail(100).min()\n",
    "            resistance = df[\"High\"].tail(100).max()\n",
    "            \n",
    "            df.to_csv(\"processed_data_with_patterns.csv\")\n",
    "            \n",
    "            mt5.shutdown()\n",
    "            return df, metrics, {\"support\": support, \"resistance\": resistance}, double_tops, double_bottoms\n",
    "        \n",
    "        except Exception as e:\n",
    "            mt5.shutdown()\n",
    "            raise Exception(f\"Error in get_eurusd_data: {str(e)}\")\n",
    "\n",
    "    def _execute(self, query):\n",
    "        try:\n",
    "            return self.get_eurusd_data()\n",
    "        except Exception as e:\n",
    "            return f\"Error analyzing EURUSD data: {str(e)}\"\n",
    "\n",
    "# EURUSD Decision Agent\n",
    "# artifact_id: f7d9a2e3-6b8c-4f13-9c2d-5e7a8f3b1e9f\n",
    "class EURUSDDecisionAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name='EURUSD Decision Agent',\n",
    "            role='Make buy/sell decisions for EURUSD based on technical analysis and news',\n",
    "            model=Grok(id='llama-3.3-70b-versatile', api_key=\"YOUR_GROQ_API_KEY\"),  # Replace with your API key\n",
    "            tools=[],\n",
    "            instructions=[\n",
    "                \"Call the EURUSD Forex Analysis Agent to retrieve EURUSD price data, technical indicators, candlestick patterns, and price patterns from MetaTrader 5.\",\n",
    "                \"Call the EURUSD News Search Agent to retrieve recent news and market sentiment for EURUSD.\",\n",
    "                \"Handle the News Search Agent's output to ensure it is a string (e.g., extract .content from RunResponse).\",\n",
    "                \"Evaluate technical signals: Buy if 50-SMA > 200-SMA, RSI < 70, MACD > Signal, and bullish candlestick patterns or Double Bottom. Sell if 50-SMA < 200-SMA, RSI > 30, MACD < Signal, and bearish candlestick patterns or Double Top.\",\n",
    "                \"Assess news sentiment: Positive (bullish, Euro recovery) supports buy; negative (bearish, USD strength) supports sell; neutral has no strong influence.\",\n",
    "                \"Make a decision: Buy if technicals are bullish and news is positive/neutral; Sell if technicals are bearish and news is negative/neutral; Hold if signals are mixed.\",\n",
    "                \"Set stop loss using 1.5x ATR or near support/resistance. Set take profit for a 2:1 reward:risk ratio or near support/resistance.\",\n",
    "                \"Format the response in markdown with tables for price metrics, technical indicators, candlestick patterns, price patterns, news summary, and trading decision.\",\n",
    "                \"Provide a rationale for the trading decision.\",\n",
    "                \"Handle errors gracefully, returning a Hold decision if agent calls fail.\",\n",
    "                \"Do not execute trades; only provide recommendations.\"\n",
    "            ],\n",
    "            description=\"Combines technical analysis and news sentiment to make EURUSD trading decisions.\",\n",
    "            show_tool_calls=False,\n",
    "            markdown=True\n",
    "        )\n",
    "        self.forex_agent = EURUSDForexAnalysisAgent()\n",
    "        self.news_agent = EURUSDNewsSearchAgent()\n",
    "\n",
    "    def make_trading_decision(self, analysis_data, news_data):\n",
    "        try:\n",
    "            df, metrics, levels, double_tops, double_bottoms = analysis_data\n",
    "            \n",
    "            if hasattr(news_data, 'content'):\n",
    "                news_summary = news_data.content\n",
    "            elif isinstance(news_data, str):\n",
    "                news_summary = news_data\n",
    "            else:\n",
    "                news_summary = str(news_data)\n",
    "            \n",
    "            latest = df.iloc[-1]\n",
    "            is_bullish_technicals = (\n",
    "                latest[\"SMA_50\"] > latest[\"SMA_200\"] and\n",
    "                latest[\"RSI\"] < 70 and\n",
    "                latest[\"MACD\"] > latest[\"MACD_Signal\"] and\n",
    "                (latest[\"Bullish_Engulfing\"] > 0 or latest[\"Morning_Star\"] > 0 or latest[\"Hammer\"] > 0)\n",
    "            )\n",
    "            is_bearish_technicals = (\n",
    "                latest[\"SMA_50\"] < latest[\"SMA_200\"] and\n",
    "                latest[\"RSI\"] > 30 and\n",
    "                latest[\"MACD\"] < latest[\"MACD_Signal\"] and\n",
    "                (latest[\"Bearish_Engulfing\"] < 0 or latest[\"Evening_Star\"] < 0 or latest[\"Shooting_Star\"] < 0)\n",
    "            )\n",
    "            \n",
    "            has_double_top = len(double_tops) > 0 and df.index[-1] - double_tops[-1][1] < 100\n",
    "            has_double_bottom = len(double_bottoms) > 0 and df.index[-1] - double_bottoms[-1][1] < 100\n",
    "            \n",
    "            news_sentiment = \"neutral\"\n",
    "            try:\n",
    "                news_summary_lower = news_summary.lower()\n",
    "                if \"bullish\" in news_summary_lower or \"euro recovery\" in news_summary_lower:\n",
    "                    news_sentiment = \"positive\"\n",
    "                elif \"bearish\" in news_summary_lower or \"usd strength\" in news_summary_lower:\n",
    "                    news_sentiment = \"negative\"\n",
    "            except AttributeError:\n",
    "                news_sentiment = \"neutral\"\n",
    "            \n",
    "            decision = {\"action\": \"Hold\", \"entry_price\": None, \"stop_loss\": None, \"take_profit\": None, \"risk_reward\": None}\n",
    "            entry_price = metrics[\"current_price\"]\n",
    "            atr = latest[\"ATR\"]\n",
    "            support = levels[\"support\"]\n",
    "            resistance = levels[\"resistance\"]\n",
    "            \n",
    "            if is_bullish_technicals and has_double_bottom and news_sentiment in [\"positive\", \"neutral\"]:\n",
    "                decision[\"action\"] = \"Buy\"\n",
    "                decision[\"entry_price\"] = entry_price\n",
    "                decision[\"stop_loss\"] = max(entry_price - 1.5 * atr, support * 0.999)\n",
    "                decision[\"take_profit\"] = min(entry_price + 3 * atr, resistance * 1.001)\n",
    "            elif is_bearish_technicals and has_double_top and news_sentiment in [\"negative\", \"neutral\"]:\n",
    "                decision[\"action\"] = \"Sell\"\n",
    "                decision[\"entry_price\"] = entry_price\n",
    "                decision[\"stop_loss\"] = min(entry_price + 1.5 * atr, resistance * 1.001)\n",
    "                decision[\"take_profit\"] = max(entry_price - 3 * atr, support * 0.999)\n",
    "            \n",
    "            if decision[\"action\"] != \"Hold\":\n",
    "                risk = abs(decision[\"entry_price\"] - decision[\"stop_loss\"])\n",
    "                reward = abs(decision[\"take_profit\"] - decision[\"entry_price\"])\n",
    "                decision[\"risk_reward\"] = reward / risk if risk > 0 else None\n",
    "            \n",
    "            # Format markdown output\n",
    "            output = f\"## EURUSD Trading Decision (M15 Timeframe, {datetime.now().strftime('%Y-%m-%d %H:%M EEST')})\\n\\n\"\n",
    "            \n",
    "            output += \"### Price Metrics\\n| Metric | Value |\\n|--------|-------|\\n\"\n",
    "            output += f\"| Current Price | {metrics['current_price']:.5f} USD |\\n\"\n",
    "            output += f\"| Daily Change | {metrics['daily_change']:.2f}% |\\n\"\n",
    "            output += f\"| Monthly Change | {metrics['monthly_change']:.2f}% |\\n\"\n",
    "            output += f\"| Volatility (Annual) | {metrics['volatility']:.2f}% |\\n\\n\"\n",
    "            \n",
    "            output += \"### Technical Indicators (Latest Values)\\n| Indicator | Value |\\n|-----------|-------|\\n\"\n",
    "            for ind in [\"SMA_50\", \"SMA_200\", \"MACD\", \"MACD_Signal\", \"RSI\", \"ADX\", \"Upper_Band\", \"Middle_Band\", \n",
    "                        \"Lower_Band\", \"SlowK\", \"SlowD\", \"CCI\", \"WilliamsR\", \"ATR\", \"CMO\", \"OBV\", \"MFI\"]:\n",
    "                value = latest[ind]\n",
    "                output += f\"| {ind} | {value:.4f if isinstance(value, (int, float)) else value} |\\n\"\n",
    "            \n",
    "            output += \"\\n### Latest Candlestick Patterns (Non-Zero)\\n| Pattern | Time | Value |\\n|---------|------|-------|\\n\"\n",
    "            for pattern in [\"Hammer\", \"Bullish_Engulfing\", \"Shooting_Star\", \"Bearish_Engulfing\", \"Doji\", \n",
    "                            \"Morning_Star\", \"Evening_Star\", \"Harami\"]:\n",
    "                if latest[pattern] != 0:\n",
    "                    output += f\"| {pattern} | {latest['Time']} | {latest[pattern]} |\\n\"\n",
    "            \n",
    "            output += \"\\n### Price Patterns (Double Top/Bottom)\\n| Pattern | First Point Time | Second Point Time | Price Level |\\n|---------|------------------|-------------------|-------------|\\n\"\n",
    "            for top in double_tops:\n",
    "                output += f\"| Double Top | {df['Time'].iloc[top[0]]} | {df['Time'].iloc[top[1]]} | ~{df['Close'].iloc[top[0]]:.4f} |\\n\"\n",
    "            for bottom in double_bottoms:\n",
    "                output += f\"| Double Bottom | {df['Time'].iloc[bottom[0]]} | {df['Time'].iloc[bottom[1]]} | ~{df['Close'].iloc[bottom[0]]:.4f} |\\n\"\n",
    "            \n",
    "            output += \"\\n### Support and Resistance Levels\\n| Level Type | Price Level |\\n|------------|-------------|\\n\"\n",
    "            output += f\"| Support | {levels['support']:.4f} |\\n\"\n",
    "            output += f\"| Resistance | {levels['resistance']:.4f} |\\n\"\n",
    "            \n",
    "            output += f\"\\n### News Summary\\n{news_summary}\\n\"\n",
    "            \n",
    "            output += \"\\n### Trading Decision\\n| Action | Entry Price | Stop Loss | Take Profit | Risk:Reward |\\n|--------|-------------|-----------|-------------|-------------|\\n\"\n",
    "            output += f\"| {decision['action']} | {decision['entry_price'] or '-'} | {decision['stop_loss'] or '-'} | {decision['take_profit'] or '-'} | {decision['risk_reward'] or '-'} |\\n\"\n",
    "            \n",
    "            output += \"\\n### Rationale\\n\"\n",
    "            output += f\"- **Technicals**: {'Bullish' if is_bullish_technicals else 'Bearish' if is_bearish_technicals else 'Mixed'} signals based on SMA, MACD, RSI, and patterns.\\n\"\n",
    "            output += f\"- **News**: {news_sentiment.capitalize()} sentiment based on recent articles.\\n\"\n",
    "            output += f\"- **Decision**: {decision['action']} recommended due to combined technical and news signals.\\n\"\n",
    "            \n",
    "            output += \"\\n### Notes\\n- Processed data saved to 'processed_data_with_patterns.csv'.\\n- Recommendation only; verify with your trading strategy.\"\n",
    "            \n",
    "            return output\n",
    "        \n",
    "        except Exception as e:\n",
    "            output = f\"## EURUSD Trading Decision Error\\n\\nError processing decision: {str(e)}\\n\\n\"\n",
    "            output += \"### Trading Decision\\n| Action | Entry Price | Stop Loss | Take Profit | Risk:Reward |\\n|--------|-------------|-----------|-------------|-------------|\\n\"\n",
    "            output += \"| Hold | - | - | - | - |\\n\\n### Notes\\n- Unable to process data; defaulting to Hold.\"\n",
    "            return output\n",
    "\n",
    "    def _execute(self, query):\n",
    "        try:\n",
    "            analysis_data = self.forex_agent.run(\"Analyze EURUSD forex prices.\").content\n",
    "            news_data = self.news_agent.run(\"Find the latest EURUSD news and market updates.\")\n",
    "            return self.make_trading_decision(analysis_data, news_data)\n",
    "        except Exception as e:\n",
    "            return f\"Error executing decision agent: {str(e)}\"\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    decision_agent = EURUSDDecisionAgent()\n",
    "    result = decision_agent.run(\"Make a buy/sell decision for EURUSD with stop loss and take profit.\")\n",
    "    print(result.content)\n",
    "\n",
    "\n",
    "NameError: name 'Grok' is not defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e04eff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\anaconda\\envs\\tensorflow\\lib\\site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "# from mlflow import pyspark\n",
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fada962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
